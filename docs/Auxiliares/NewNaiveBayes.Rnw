\documentclass[12pt]{article}         % the type of document and font size (default 10pt)
\usepackage[margin=1.0in]{geometry}   % sets all margins to 1in, can be changed
\usepackage{moreverb}                 % for verbatimtabinput -- LaTeX environment
\usepackage{rotating}
\usepackage{url}     
\usepackage{hyperref}
% for \url{} command
\usepackage{amssymb}                  % for many mathematical symbols
\usepackage[pdftex]{lscape}           % for landscaped tables
\usepackage{longtable}
\usepackage[dvipsnames]{xcolor}
\usepackage{multicol,multirow}
\usepackage{tikz}
% for tables that break over multiple pages
\title{Aplicacion Naive Bayes}  % to specify title
\author{$\blacktriangleright\because\therefore\because\therefore\because\therefore\because\therefore\because\therefore\because\therefore\because\therefore\because\therefore\because\blacktriangleleft$}          % to specify author(s)
\begin{document}                      % document begins here
\SweaveOpts{concordance=TRUE}

% If .nw file contains graphs: To specify that EPS/#pdf graph files are to be 
% saved to 'graphics' sub-folder
%     NOTE: 'graphics' sub-folder must exist prior to Sweave step
%\SweaveOpts{prefix.string=graphics/plot}

% If .nw file contains graphs: to modify (shrink/enlarge} size of graphics 
% file inserted
%         NOTE: can be specified/modified before any graph chunk
\setkeys{Gin}{width=1.0\textwidth}

\maketitle              % makes the title
\tableofcontents        % inserts TOC (section, sub-section, etc numbers and titles)
%\listoftables           % inserts LOT (numbers and captions)
%\listoffigures          % inserts LOF (numbers and captions)
%                        %     NOTE: graph chunk must be wrapped with \begin{figure}, 
%                        %  \end{figure}, and \caption{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Where everything else goes
%===================================================================================
\section{Lectura de las Bases de Datos}
Se cargan las librearias necesarias para poder procesar y sistematizar las bases de datos

<<echo = FALSE>>=
#===========================================================================
setwd("~/Desktop/Datos Elisa")
#setwd("~/Escritorio/Datos Elisa")
#===========================================================================
library(ggplot2);   library(dplyr);         library(readxl);
library(pastecs);   library(sciplot);       library(MASS);
library(gridExtra); library("gplots");      library("lattice");
#library(car);       library(gridExtra);     library(lattice);
library(corrplot);  library(readr);         library(readxl);   
#library(rvest);    library(RSQLite); 
library(DBI);    
#library(xml2);    
#library(RCurl);     
#library(devtools);
library(ggplot2);   library(datasets);      library(dplyr);
library(sciplot);   library(scatterplot3d); #library("car")
library(psych);     library("gplots");      library("plotrix")
library(gplots);    library(moments);       #library(univariateML)
#===========================================================================
dataset1 <- read_excel("BDD_Definitiva.xlsx")
dataset <- na.omit(dataset1)
@


<<echo = FALSE>>=
dataset$Secuencia = factor(dataset$Secuencia,
                           levels = c('CAACGG','CAACTG','TAACGG','TAACTG'),
                           labels = c('CAACGG','CAACTG','TAACGG','TAACTG'))
colnames(dataset) <- c('Sequence', 'Position', 'Gen_Id1','Gen_Id2', 
                       'Description', 'BasalExp','DigitVerif')
#===========================================================================
datosn <- dataset$Position;
d <- as.numeric(datosn);
dataset$Position <- d
#===========================================================================
#summary(dataset)
#===========================================================================
dataset$DigitVerif <- dataset$Sequence
dataset$DigitVerif = factor(dataset$DigitVerif,
                            levels = c('CAACGG','CAACTG','TAACGG','TAACTG'),
                            labels = c(1,2,3,4))
#===========================================================================
#summary(dataset)
#View(dataset)
#===========================================================================
CtoDatos <- dataset[,c('Sequence','DigitVerif','Position','BasalExp','Gen_Id1')]
colnames(CtoDatos) <- c('Sequence','CodedSeq','Position','BasalExp','Gen_Id')
#View(CtoDatos)
#summary(CtoDatos)
bdd <- CtoDatos
#===========================================================================
nbreaks <- 40
#===========================================================================
@

\section{Grafica de datos}

\subsection{Posici\'on}

<<echo = FALSE, fig=TRUE>>=
tP <- hist(bdd$Position, breaks = nbreaks, col= rainbow(15,0.7), main = 'Position')
#print(tP)
@


<<echo = FALSE, fig=FALSE>>=
tBE <- hist(bdd$BasalExp, breaks = nbreaks, col= rainbow(15,0.7), main = 'BasalExpresion')
#print(tBE)
@

Conteo de datos por Clase

<<echo = FALSE>>=
counts<- table(bdd$Sequence)
t <- table(bdd$Sequence)
prop.table(t)*100
@



<<echo = FALSE>>=
LF <- bdd$Position
#summary(LF)
hist(LF, breaks = nbreaks,col= rainbow(15,0.7), main = 'Raw Position' )
CLF <- -LF
@


Posici\'on normalizada

<<echo = FALSE>>=
m1 <- 0; #mean(CLF)
de1 <- sd(CLF)
NormPosition <- (CLF-m1)/de1
tNP <- hist(NormPosition, breaks = nbreaks, col= rainbow(15,0.7), main = ' Estandarized Position')
#summary(NormPosition)
#print(tNP)
@

$Log_{2}$ Posici\'on Normalizada

<<echo = FALSE, fig=TRUE>>=
Log2NP <- log2(NormPosition)
summary(Log2NP)
tLNP <- hist(Log2NP, breaks = nbreaks, col= rainbow(15,0.7), main = ' Log2 Transformed Position')
#print(tLNP)
@

\subsection{Expresi\'on Basal}

Expresi\'on Basal Normalizada

<<echo = FALSE, fig=FALSE>>=
BE <- bdd$BasalExp
hist(BE,breaks = nbreaks, col= rainbow(6,0.7), main = 'Raw Basal Expresion' )
#summary(BE)
@

Se normalizan

<<echo = FALSE>>=
mBE <- mean(BE)
deBE <- sd(BE)
NormBE <- (BE-mBE)/deBE
nBE <- length(NormBE)
@

Ahora se transforma la expresi\'on basal  aplicando el $Log_{2}$ 

<<echo = FALSE, fig=TRUE>>=
Log2BE <- log2(BE)
hist(Log2BE, breaks = nbreaks, col= rainbow(15,0.7), main = ' Log2 Transformed Basal Expresion')
@


<<echo = FALSE, fig=FALSE>>=
tL2BE <- hist(Log2BE, breaks = nbreaks)
#print(tL2BE)
@


<<echo = FALSE, fig=TRUE>>=
#===========================================================================
library("fitdistrplus"); library("MASS"); library("survival")
boxplot(Log2BE, main = 'Log2BE' )
@


<<echo = FALSE, fig= true>>=
tst<- Log2BE
boxplot(tst, main = 'Translated Log2BE')
summary(tst)
hist(tst, breaks = nbreaks, col= rainbow(15,0.7), main = 'Log2 Transformed Basal Expresion')
#===========================================================================
@


\section{Ajustando Modelos}



<<echo = FALSE, fig=TRUE>>=
plotdist(tst, histo = TRUE, demp = TRUE)
descdist(tst)
#===========================================================================
@


\subsection{ Ajustando una Distribucion Normal}

<<echo = FALSE>>=
#===========================================================================
fw5<-fitdist(tst, "norm")
summary(fw5)
@


<<echo = FALSE, fig=TRUE>>=
denscomp(fw5)
@


<<echo = FALSE, fig=TRUE>>=
cdfcomp(fw5)
@


<<echo = FALSE, fig=TRUE>>=
qqcomp(fw5)
@


<<echo = FALSE, fig=TRUE>>=
ppcomp(fw5)
@


Los resultados del ajuste son: 

<<echo = FALSE>>=
summary(fw5)
@

<<echo = FALSE>>=
quantile(fw5, probs = 0.05)
@

<<echo = FALSE>>=
quantile(tst, probs = 0.05)
@


<<echo = FALSE>>=
#dist1 <- mlnorm(x=tst)
#summary(dist1)
@


<<echo = FALSE>>=
vals <- fw5$estimate
Media <- as.numeric(vals[1])
SDev <- as.numeric(vals[2])
@

Los datos del art\'iculo principal son sim\'etricos y se distribuyen normal casi perfectamente, con lo que es relativamente m\'as sencillo determinar los valores que ser\'an considerados de frecuencias bajas, medias y altas. Para nuestro caso la distribuci\'on emp\'irica es asim\'etrica, por eso no es posible replicar los mismos criterios.


%Cuantiles con el modelo ajustado
<<echo = FALSE>>=
CuantilesA <- matrix(0,8,2)
colnames(CuantilesA) <- c('LimInf','LimSup')
rownames(CuantilesA) <- c('65','70','75','80','85','90','95','99')
qadj0175 <- quantile(fw5, probs = 0.175); t <- qadj0175[[1]];qadj0175 <-  t[[1]]-1;
CuantilesA[1,1] <- qadj0175; 
qadj0825 <- quantile(fw5, probs = 0.825); t <- qadj0825[[1]];qadj0825 <-  t[[1]]-1;
CuantilesA[1,2] <- qadj0825; 
qadj015  <- quantile(fw5, probs = 0.15);  t <- qadj015[[1]]; qadj015  <-  t[[1]]-1;
CuantilesA[2,1] <- qadj015; 
qadj085  <- quantile(fw5, probs = 0.85);  t <- qadj085[[1]]; qadj085  <-  t[[1]]-1;
CuantilesA[2,2] <- qadj085; 
qadj0125 <- quantile(fw5, probs = 0.125); t <- qadj0125[[1]];qadj0125 <-  t[[1]]-1;
CuantilesA[3,1] <- qadj0125; 
qadj0875 <- quantile(fw5, probs = 0.875); t <- qadj0875[[1]];qadj0875 <-  t[[1]]-1;
CuantilesA[3,2] <- qadj0875; 
qadj001  <- quantile(fw5, probs = 0.1);   t <- qadj001[[1]]; qadj001  <-  t[[1]]-1;
CuantilesA[4,1] <- qadj001; 
qadj009  <- quantile(fw5, probs = 0.9);   t <- qadj009[[1]]; qadj009  <-  t[[1]]-1;
CuantilesA[4,2] <- qadj009; 
qadj075  <- quantile(fw5, probs = 0.075); t <- qadj075[[1]]; qadj075  <-  t[[1]]-1;
CuantilesA[5,1] <- qadj075; 
qadj0925 <- quantile(fw5, probs = 0.925); t <- qadj0925[[1]];qadj0925 <-  t[[1]]-1;
CuantilesA[5,2] <- qadj0925; 
qadj005  <- quantile(fw5, probs = 0.05);  t <- qadj005[[1]]; qadj005  <-  t[[1]]-1;
CuantilesA[6,1] <- qadj005; 
qadj095  <- quantile(fw5, probs = 0.95);  t <- qadj095[[1]]; qadj095  <-  t[[1]]-1;
CuantilesA[6,2] <- qadj095; 
qadj025  <- quantile(fw5, probs = 0.025); t <- qadj025[[1]]; qadj025  <-  t[[1]]-1;
CuantilesA[7,1] <- qadj025; 
qadj0975 <- quantile(fw5, probs = 0.975); t <- qadj0975[[1]];qadj0975 <-  t[[1]]-1;
CuantilesA[7,2] <- qadj0975; 
qadj005  <- quantile(fw5, probs = 0.005); t <- qadj005[[1]]; qadj005  <-  t[[1]]-1;
CuantilesA[8,1] <- qadj005; 
qadj0995 <- quantile(fw5, probs = 0.995); t <- qadj0995[[1]];qadj0995 <-  t[[1]]-1;
CuantilesA[8,2] <- qadj0995; 
print(CuantilesA)
@



Cuantiles con los datos
<<echo = FALSE>>=
CuantilesD <- matrix(0,8,2)
colnames(CuantilesD) <- c('LimInf','LimSup')
rownames(CuantilesD) <- c('65','70','75','80','85','90','95','99')
qdat0175 <- quantile(tst, probs = 0.175);  t <- qdat0175[[1]]; qdat0175 <- t-1;
CuantilesD[1,1] <- qdat0175; # 65% INFERIOR
qdat0825 <- quantile(tst, probs = 0.825);  t <- qdat0825[[1]]; qdat0825 <- t-1;
CuantilesD[1,2] <- qdat0825;# 65% SUPERIOR
qdat015  <- quantile(tst, probs = 0.15);   t <- qdat015[[1]];  qdat015  <- t-1;
CuantilesD[2,1] <- qdat015;# 70% INFERIOR
qdat085  <- quantile(tst, probs = 0.85);   t <- qdat085[[1]];  qdat085  <- t-1;
CuantilesD[2,2] <- qdat085; # 70% SUPERIOR
qdat0125 <- quantile(tst, probs = 0.125);  t <- qdat0125[[1]]; qdat0125 <- t-1;
CuantilesD[3,1] <- qdat0125; # 75% INFERIOR
qdat0875 <- quantile(tst, probs = 0.875);  t <- qdat0875[[1]]; qdat0875 <- t-1;
CuantilesD[3,2] <- qdat0875; # 75% SUPERIOR
qdat001  <- quantile(tst, probs = 0.1);    t <- qdat001[[1]];  qdat001  <- t-1;
CuantilesD[4,1] <- qdat001; # 80% INFERIOR
qdat09   <- quantile(tst, probs = 0.9);    t <- qdat09[[1]];   qdat09   <- t-1;
CuantilesD[4,2] <- qdat09; # 80% SUPERIOR
qdat075  <- quantile(tst, probs = 0.075);  t <- qdat075[[1]];  qdat075  <- t-1;
CuantilesD[5,1] <- qdat075; # 85% INFERIOR
qdat0925 <- quantile(tst, probs = 0.925);  t <- qdat0925[[1]]; qdat0925 <- t-1;
CuantilesD[5,2] <- qdat0925; # 85% SUPERIOR
qdat005  <- quantile(tst, probs = 0.05);   t <- qdat005[[1]];  qdat005  <- t-1;
CuantilesD[6,1] <- qdat005; # 90% INFERIOR
qdat095  <- quantile(tst, probs = 0.95);   t <- qdat095[[1]];  qdat095  <- t-1;
CuantilesD[6,2] <- qdat095; # 90% SUPERIOR
qdat025  <- quantile(tst, probs = 0.025);  t <- qdat025[[1]];  qdat025  <- t-1;
CuantilesD[7,1] <- qdat025; # 95% INFERIOR
qdat0975 <- quantile(tst, probs = 0.975);  t <- qdat0975[[1]]; qdat0975 <- t-1;
CuantilesD[7,2] <- qdat0975; # 95% SUPERIOR
qdat005  <- quantile(tst, probs = 0.005);  t <- qdat005[[1]];  qdat005  <- t-1;
CuantilesD[8,1] <- qdat005; # 99% INFERIOR
qdat0995 <- quantile(tst, probs = 0.995);  t <- qdat0995[[1]]; qdat0995 <- t-1;
CuantilesD[8,2] <- qdat0995; # 99% SUPERIOR
print(CuantilesD)
#data.frame(CuantilesD)
@

\subsection{Presentaci\'on de tablas}

Lo que nos da las siguientes tablas

<<echo = FALSE, fig=TRUE>>=
hist(tst, breaks = nbreaks, col= rainbow(15,0.7), xlim=c(-3,15),
     main = 'Log2 Transformed Basal Expresion - ADJUSTED', lty=9)
#===========================================================================
abline(v=CuantilesA[1,1], lty=2, col="darkgoldenrod4"); # 65% INFERIOR
abline(v=CuantilesA[1,2], lty=2, col="darkgoldenrod4"); # 65% SUPERIOR
abline(v=CuantilesA[2,1], lty=2, col="darkblue"); # 70% INFERIOR
abline(v=CuantilesA[2,2], lty=2, col="darkblue") # 70% SUPERIOR
abline(v=CuantilesA[3,1], lty=2, col="aquamarine4"); # 75% INFERIOR
abline(v=CuantilesA[3,2], lty=2, col="aquamarine4"); # 75% SUPERIOR
abline(v=CuantilesA[4,1], lty=2, col="green");  # 80% INFERIOR
abline(v=CuantilesA[4,2], lty=2, col="green"); # 80% SUPERIOR
abline(v=CuantilesA[5,1], lty=2, col="brown"); # 85% INFERIOR
abline(v=CuantilesA[5,2], lty=2, col="brown"); # 85% SUPERIOR
abline(v=CuantilesA[6,1], lty=2, col="red");  # 90% INFERIOR
abline(v=CuantilesA[6,2], lty=2, col="red"); # 90% SUPERIOR
abline(v=CuantilesA[7,1], lty=2, col="blue");  # 95% INFERIOR
abline(v=CuantilesA[7,2], lty=2, col="blue"); # 95% SUPERIOR
abline(v=CuantilesA[8,1], lty=2, col="orange");  # 99% INFERIOR
abline(v=CuantilesA[8,2], lty=2, col="orange"); # 99% SUPERIOR
legend("topright",
       legend=c("65%","70%","75%","80%","85%","90%","95%","99%"), 
       pch=c(1,2,3,4,5,6,7,8),
       col=c("darkgoldenrod4","darkblue","aquamarine4",
             "green", "brown","red","blue","orange"))
@

<<echo = FALSE, fig=TRUE>>=
hist(tst, breaks = nbreaks, col= rainbow(15,0.7), xlim=c(-3,15),
     main = 'Log2 Transformed Basal Expresion - DATA', lty=9)
#===========================================================================
abline(v=CuantilesD[1,1], lty=2, col="darkgoldenrod4"); # 65% INFERIOR
abline(v=CuantilesD[1,2], lty=2, col="darkgoldenrod4"); # 65% SUPERIOR
abline(v=CuantilesD[2,1], lty=2, col="darkblue");  # 70% INFERIOR
abline(v=CuantilesD[2,2], lty=2, col="darkblue"); # 70% SUPERIOR
abline(v=CuantilesD[3,1], lty=2, col="aquamarine4");  # 75% INFERIOR
abline(v=CuantilesD[3,2], lty=2, col="aquamarine4"); # 75% SUPERIOR
abline(v=CuantilesD[4,1], lty=2, col="green");  # 80% INFERIOR
abline(v=CuantilesD[4,2], lty=2, col="green"); # 80% SUPERIOR
abline(v=CuantilesD[5,1], lty=2, col="brown");  # 85% INFERIOR
abline(v=CuantilesD[5,2], lty=2, col="brown"); # 85% SUPERIOR
abline(v=CuantilesD[6,1], lty=2, col="red");  # 90% INFERIOR
abline(v=CuantilesD[6,2], lty=2, col="red"); # 90% SUPERIOR
abline(v=CuantilesD[7,1], lty=2, col="blue");  # 95% INFERIOR
abline(v=CuantilesD[7,2], lty=2, col="blue"); # 95% SUPERIOR
abline(v=CuantilesD[8,1], lty=2, col="orange");  # 99% INFERIOR
abline(v=CuantilesD[8,2], lty=2, col="orange"); # 99% SUPERIOR
legend("topright",
       legend=c("65%","70%","75%","80%","85%","90%","95%","99%"), 
       pch=c(1,2,3,4,5,6,7,8),
       col=c("darkgoldenrod4","darkblue","aquamarine4",
             "green", "brown","red","blue","orange"))
@



<<echo = FALSE, fig=TRUE>>=
hist(tst, breaks = nbreaks, col= rainbow(15,0.7), xlim=c(-3,15),
     main = 'Log2 Transformed Basal Expresion', lty=9)
#===========================================================================
#abline(v=1.130931, lty=2, col="darkgoldenrod4"); abline(v=5.5288913, lty=2, col="darkgoldenrod4")
abline(v=CuantilesD[2,1], lty=2, col="darkblue"); abline(v=CuantilesD[2,2], lty=2, col="darkblue")
#abline(v=0.7441547, lty=2, col="aquamarine4"); abline(v=6.536406, lty=2, col="aquamarine4")
#abline(v=0.4624797, lty=2, col="green"); abline(v=6.969012, lty=2, col="green")
abline(v=CuantilesD[5,1], lty=2, col="brown"); abline(v=CuantilesD[5,2], lty=2, col="brown")
#abline(v=-0.8272507, lty=2, col="red"); abline(v=8.176996, lty=2, col="red")
#abline(v=-0.5713549, lty=2, col="blue"); abline(v=9.573605, lty=2, col="blue")
#abline(v=-0.1910198, lty=2, col="orange"); abline(v=12.43287, lty=2, col="orange")
legend("topright",
       legend=c(#"65%",
                "70%",
                #"75%",
                #"80%",
                "85%"),
                #"90%",
                #"95%",
                #"99%"
#                ), 
       pch=c(1,2),#3,4,5,6,7,8),
       col=c(#"darkgoldenrod4",
#             "darkblue","aquamarine4","green",
             "brown"
             #,"red","blue","orange"
             ))
@


<<echo = FALSE, fig=TRUE>>=
hist(tst, breaks = nbreaks, col= rainbow(15,0.7), xlim=c(-3,15),
     main = 'Log2 Transformed Basal Expresion', lty=9)
#===========================================================================
#abline(v=1.130931, lty=2, col="darkgoldenrod4"); abline(v=5.5288913, lty=2, col="darkgoldenrod4")
abline(v=CuantilesD[2,1], lty=2, col="darkblue"); abline(v=CuantilesD[2,2], lty=2, col="darkblue")
#abline(v=0.7441547, lty=2, col="aquamarine4"); abline(v=6.536406, lty=2, col="aquamarine4")
#abline(v=0.4624797, lty=2, col="green"); abline(v=6.969012, lty=2, col="green")
abline(v=CuantilesD[5,1], lty=2, col="brown"); abline(v=CuantilesD[5,2], lty=2, col="brown")
#abline(v=-0.8272507, lty=2, col="red"); abline(v=8.176996, lty=2, col="red")
#abline(v=-0.5713549, lty=2, col="blue"); abline(v=9.573605, lty=2, col="blue")
#abline(v=-0.1910198, lty=2, col="orange"); abline(v=12.43287, lty=2, col="orange")
legend("topright",
       legend=c(#"65%",
                "70%",
                #"75%",
                #"80%",
                "85%"),
                #"90%",
                #"95%",
                #"99%"
#                ), 
       pch=c(1,2),#3,4,5,6,7,8),
       col=c(#"darkgoldenrod4",
#             "darkblue","aquamarine4","green",
             "brown"
             #,"red","blue","orange"
             ))
@



<<echo = FALSE, fig=TRUE>>=
hist(tst, breaks = nbreaks, col= rainbow(15,0.7), xlim=c(-3,15),
     main = 'Log2 Transformed Basal Expresion - ADJUSTED', lty=9)
#===========================================================================
abline(v=CuantilesA[1,1], lty=2, col="darkgoldenrod4"); # 65% INFERIOR
abline(v=CuantilesA[1,2], lty=2, col="darkgoldenrod4"); # 65% SUPERIOR
#abline(v=CuantilesA[2,1], lty=2, col="darkblue"); # 70% INFERIOR
#abline(v=CuantilesA[2,2], lty=2, col="darkblue") # 70% SUPERIOR
#abline(v=CuantilesA[3,1], lty=2, col="aquamarine4"); # 75% INFERIOR
#abline(v=CuantilesA[3,2], lty=2, col="aquamarine4"); # 75% SUPERIOR
abline(v=CuantilesA[4,1], lty=2, col="green");  # 80% INFERIOR
abline(v=CuantilesA[4,2], lty=2, col="green"); # 80% SUPERIOR
#abline(v=CuantilesA[5,1], lty=2, col="brown"); # 85% INFERIOR
#abline(v=CuantilesA[5,2], lty=2, col="brown"); # 85% SUPERIOR
#abline(v=CuantilesA[6,1], lty=2, col="red");  # 90% INFERIOR
#abline(v=CuantilesA[6,2], lty=2, col="red"); # 90% SUPERIOR
#abline(v=CuantilesA[7,1], lty=2, col="blue");  # 95% INFERIOR
#abline(v=CuantilesA[7,2], lty=2, col="blue"); # 95% SUPERIOR
#abline(v=CuantilesA[8,1], lty=2, col="orange");  # 99% INFERIOR
#abline(v=CuantilesA[8,2], lty=2, col="orange"); # 99% SUPERIOR
legend("topright",
       legend=c("65%","80%"), 
       pch=c(1,2),
       col=c("darkgoldenrod4","green"))
@

<<echo = FALSE, fig=TRUE>>=
hist(tst, breaks = nbreaks, col= rainbow(15,0.7), xlim=c(-3,15),
     main = 'Log2 Transformed Basal Expresion - DATA', lty=9)
#===========================================================================
abline(v=CuantilesD[1,1], lty=2, col="darkgoldenrod4"); # 65% INFERIOR
abline(v=CuantilesD[1,2], lty=2, col="darkgoldenrod4"); # 65% SUPERIOR
#abline(v=CuantilesD[2,1], lty=2, col="darkblue");  # 70% INFERIOR
#abline(v=CuantilesD[2,2], lty=2, col="darkblue"); # 70% SUPERIOR
#abline(v=CuantilesD[3,1], lty=2, col="aquamarine4");  # 75% INFERIOR
#abline(v=CuantilesD[3,2], lty=2, col="aquamarine4"); # 75% SUPERIOR
abline(v=CuantilesD[4,1], lty=2, col="green");  # 80% INFERIOR
abline(v=CuantilesD[4,2], lty=2, col="green"); # 80% SUPERIOR
#abline(v=CuantilesD[5,1], lty=2, col="brown");  # 85% INFERIOR
#abline(v=CuantilesD[5,2], lty=2, col="brown"); # 85% SUPERIOR
#abline(v=CuantilesD[6,1], lty=2, col="red");  # 90% INFERIOR
#abline(v=CuantilesD[6,2], lty=2, col="red"); # 90% SUPERIOR
#abline(v=CuantilesD[7,1], lty=2, col="blue");  # 95% INFERIOR
#abline(v=CuantilesD[7,2], lty=2, col="blue"); # 95% SUPERIOR
#abline(v=CuantilesD[8,1], lty=2, col="orange");  # 99% INFERIOR
#abline(v=CuantilesD[8,2], lty=2, col="orange"); # 99% SUPERIOR
legend("topright",
       legend=c("65%","80%"), 
       pch=c(1,2),
       col=c("darkgoldenrod4","green"))
@


\subsection{Valores Altos, Moderadamente Altos, Bajos y Moderadamente Bajos}


Cuantiles con el modelo ajustado
<<echo = FALSE>>=
print(CuantilesA)
@

Con base en la secci\'on anterior, se tienen que la expresi\'on basal, centrados y transformados ($Log_{2}$), tienen una distribuci\'on Normal y los cuantiles para los valores $65,70,75,80,85,90,95$ y $99$ por ciento se propone que los valores moderados altos (bajos )sean aquellos que se encuentran entre el $65\%$ y $80\%$, mientras que los valores muy altos (bajos) aquellos superiores al $80\%$: 
\begin{itemize}
\item Very Low Expression: $\left[-\infty,-0.53752025\right)$,
\item Moderately Low Expression: $\left[-0.537552025,0.13093097\right)$,
\item Moderate Expresion: $\left[0.13093097,4.528913\right)$,
\item Moderately High Expression: $\left[4.528913,5.969012\right)$,
\item Very High Expression: $\left[5.969012,\infty\right)$.
\end{itemize}

Cuantiles con los datos

<<echo = FALSE>>=
print(CuantilesD)
@


Con base en cualquiera de las dos opciones, se calcula la probabilidad de que dada una expresi\'on basal ($Log_{2}$) se pueda determinar a qu\'e motif pertenece, esto por medio del Teorema de Bayes. 


Para lo anterio consideremos una partici\'on para el dominio de las \textit{Expresiones Basales}: $Y=\left\{y_{1},y_{2},\ldots,y_{n}\right\}$, y una partici\'on para el dominio de las posiciones de los genes: $X=\left\{x_{1},x_{2},\ldots,x_{m}\right\}$. Adem\'as se tienen cuatro clases $\left\{C_{1},C_{2},C_{3},C_{4}\right\}$, estas clases corresponden a los motifs: $\left\{CAACGG,CAACTG,TAACGG,TAACTG\right\}$ respectivamente.

Si se hacen las siguientes consideraciones en t\'erminos de la notaci\'on: 
\begin{itemize}
\item $HB$ para las posiciones de valores altos, 
\item $HMB$ para las posiciones de valores moderados altos, 
\item $MB$ para las posiciones de valores moderados, 
\item $LMB$ para las posiciones de valores moderados bajos, 
\item $LB$ para las posiciones de valores bajos,
\end{itemize}

estos dependen de los umbrales definidos en $I$ y $II$. 


Para cada una de las clases $C_{i}$, $i=1,2,3,4$ es posible determinar:

\begin{eqnarray}\label{Eq.Bayes1}
P\left[\textrm{pertenecer a la clase }C_{i}| HB\right]=\frac{P\left[HB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[HB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}

\begin{eqnarray}\label{Eq.Bayes2}
P\left[\textrm{pertenecer a la clase }C_{i}| HMB\right]=\frac{P\left[HMB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[HMB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}


\begin{eqnarray}\label{Eq.Bayes3}
P\left[\textrm{pertenecer a la clase }C_{i}| MB\right]=\frac{P\left[MB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[MB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}

\begin{eqnarray}\label{Eq.Bayes4}
P\left[\textrm{pertenecer a la clase }C_{i}| LMB\right]=\frac{P\left[LMB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[LMB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}
y
\begin{eqnarray}\label{Eq.Bayes5}
P\left[\textrm{pertenecer a la clase }C_{i}| LB\right]=\frac{P\left[LB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[LB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}


Incluso para cada elemento de $Y$:

\begin{eqnarray}\label{Eq.BasalClase}
P\left[\textrm{pertenecer a la clase }C_{i}| y_{k}\right]=\frac{P\left[y_{k}|C_{i}\right]P\left[C_{i}\right]}{\sum_{k=1}^{n}P\left[y_{k}|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}
para $k=1,2,\ldots,n$, donde las clases corresponden a los 4 diferentes motif's que se tienen. 


\subsection{Calculo de Probabilidades}

El procedimiento seguido fue el siguiente:
  
  \begin{itemize}
\item[I. ] Se tienen $N$ valores para la expresi\'on basal, $\left\{b_{1},b_{2},\ldots,b_{N}\right\}$, con estos se calcula tanto la media como la varianza muestral, mismas que se denotan por $\overline{B}$ y $S_{b}^{2}$. A continuaci\'on se normalizaron es decir, se les resto el valor de la media y se dividieron por la desviaci\'on est\'andar muestral:

\begin{eqnarray}
\tilde{b}_{i}=\frac{b_{i}-\overline{B}}{S_{b}},
\end{eqnarray}
posteriormente se les aplic\'o $Log_{2}$
\begin{eqnarray}
\hat{b}_{i}=Log_{2}\left(\tilde{b}_{i}\right).
\end{eqnarray}

\item[II. ] Con la ayuda del programa R-Statistics, se encontr\'o la mejor partici\'on que permite obtener una representaci\'on gr\'afica apropiada de los datos transformados, esto se obtiene al considerar $n=40$ como el tama\~no de la partici\'on que permite el mejor gr\'afico de los datos ahora llamados \textit{Log2 Transformed Basal Expresion}

\item[III. ] Se calculan las probabilidades de pertenecer a una de las cuatro clases $C_{1},C_{2},C_{3}, C_{4}$

\item[IV. ] Para cada una de las clases, considerando la partici\'on $X=\left\{x_{1},x_{2},\ldots,x_{m}\right\}$ se calculan las probabilidades de estar en $LB$, $LMB$, $MB$ $HMB$ y $HB$, es decir, se calculan las probabilidades $P\left[LB|C_{i}\right]$, $P\left[LMB|C_{i}\right]$,$P\left[HMB|C_{i}\right]$ y $P\left[HB|C_{i}\right]$, para $i=1,2,3,4$.


\item[V. ] Se utilizan las ecuaciones \ref{Eq.Bayes1}, \ref{Eq.Bayes2}, \ref{Eq.Bayes3}, \ref{Eq.Bayes4} y \ref{Eq.Bayes5}  para determinar las probabilidades de pertenecer a una de las clases $C_{i}$ dado que se sabe que se toma un valor de alta/baja expresi\'on basal

\item[VI. ] Para cada una de las clases, se calcula la probabilidad de tomar un valor en la clase, suponiendo un muestreo con reemplazo, es decir, se calculan las probabilidades $P\left[y_{k}|C_{i}\right]$, para $i=1,2,3,4$, para $k=1,2,\ldots,N$.

\item[VII. ] Con las probabilidades calculadas en el paso anterior se calculala probabilidad de pertenecer a una de las cuatro clases, considerando que se conoce el valor de la expresi\'on basal, esto se logra por medio de la ecuaci\'on \label{Eq.Basal-Clase}.
\end{itemize}

\subsection{Preguntas abiertas}

Las preguntas que quedan a\'un queda sin responder son las siguientes: 

\begin{itemize}
\item[1. ] Dado el valor de la posici\'on de un gen, es posible determinar a qu\'e motif pertenece?
\begin{eqnarray}
P\left[C_{i}|p_{i}\right]
\end{eqnarray}
donde $p_{1},p_{2},\ldots,p_{M}$ son los valores conocidos que se tienen para las posiciones de los genes, y $C_{i}, i=1,2,3,4$ corresponden a los motif's.

\item[2. ] Dado el valor de la posici\'on de un gen, es posible determinar que rango de expresi\'on basal tiene: \textit{Bajo, Bajo Moderado, Alto Moderado, Alto}?
\begin{eqnarray}
P\left[LB|p_{i}\right],P\left[LMB|p_{i}\right],P\left[HMB|p_{i}\right],P\left[HB|p_{i}\right]
\end{eqnarray}

\end{itemize}


\subsection{Respondiendo las preguntas}

\subsubsection{Clases/Motif's}
<<echo = TRUE>>=
counts<- table(bdd$Sequence)
PropSeq <- table(bdd$Sequence)
prop.table(PropSeq)
PC <- prop.table(PropSeq)
#print(PropSeq)
@

De lo anterior se desprende 
\begin{eqnarray*}
P\left[C_{1}\right]=0.05339105\\
P\left[C_{2}\right]=0.28427128\\
P\left[C_{3}\right]=0.07503608\\
P\left[C_{4}\right]=0.58730159
\end{eqnarray*}

\subsubsection{Bajas, Bajas Moderadas, Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: Todos los Datos}

Ahora contemos la cantidad de elementos que hay en las clases $HB,HMB,MB,LMB,LB$,
\begin{itemize}
\item Very Low Expression: $\left[-\infty,-0.53752025\right)$,
\item Moderately Low Expression: $\left[-0.537552025,0.13093097\right)$,
\item Moderate Expresion: $\left[0.13093097,4.528913\right)$,
\item Moderately High Expression: $\left[4.528913,5.969012\right)$,
\item Very High Expression: $\left[5.969012,\infty\right)$.
\end{itemize}


<<echo = FALSE>>=
tt1 <- min(tst)
VLI <- tt1
VLS <- CuantilesD[4,1] - 0.0000001
MLI <- CuantilesD[4,1]
MLS <- CuantilesD[1,1] - 0.0000001
MI  <- CuantilesD[1,1]
MS  <- CuantilesD[1,2] - 0.0000001
MHI <- CuantilesD[1,2]
MHS <- CuantilesD[4,2] - 0.0000001
VHI <- CuantilesD[4,2]
VHS <- max(tst)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tst)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tst[i]>=VLI) & (tst[i]<=VLS)){ContVL<- ContVL+1;}
  if((tst[i]>=MLI) & (tst[i]<=MLS)){ContML<- ContML+1;}
  if((tst[i]>=MI)  & (tst[i]<=MS)){ContM <- ContM+1;}
  if((tst[i]>=MHI) & (tst[i]<=MHS)){ContMH<- ContMH+1;}
  if((tst[i]>=VHI) & (tst[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
Conteo <- matrix(0,2,6);
Conteo[1,1] <- ContVL
Conteo[1,2] <- ContML
Conteo[1,3] <- ContM
Conteo[1,4] <- ContMH
Conteo[1,5] <- ContVH
Conteo[1,6] <- sum(Conteo[1,])
Conteo[2,1] <- ContVL/N;
Conteo[2,2] <- ContML/N;
Conteo[2,3] <- ContM/N
Conteo[2,4] <- ContMH/N;
Conteo[2,5] <- ContVH/N;
Conteo[2,6] <- sum(Conteo[2,])
colnames(Conteo) <- c('VL','ML','M','MH','VH','Ttl')
rownames(Conteo) <- c('fr','Prob')
print(Conteo)
ProbClEB <- Conteo
@

<<echo = FALSE>>=
#dataset <- cbind(CtoDatos,tt);
dataset <- cbind(bdd,tst);
summary(dataset)
@


\subsubsection{Bajas, Bajas Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: $C_{1}$}



<<echo = FALSE>>=
### Secuencia CAACGG
datos1   <- dataset %>% filter(dataset$Sequence=='CAACGG'); summary(datos1)
tt <- datos1$tst
summary(tt)
@



<<echo = FALSE>>=
tt1 <- min(tt)
VLI <- tt1
VLS <- CuantilesD[4,1] - 0.0000001
MLI <- CuantilesD[4,1]
MLS <- CuantilesD[1,1] - 0.0000001
MI  <- CuantilesD[1,1]
MS  <- CuantilesD[1,2] - 0.0000001
MHI <- CuantilesD[1,2]
MHS <- CuantilesD[4,2] - 0.0000001
VHI <- CuantilesD[4,2]
VHS <- max(tt)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tt)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tt[i]>=VLI) & (tt[i]<=VLS)){ContVL<- ContVL+1;}
  if((tt[i]>=MLI) & (tt[i]<=MLS)){ContML<- ContML+1;}
  if((tt[i]>=MI)  & (tt[i]<=MS)){ContM <- ContM+1;}
  if((tt[i]>=MHI) & (tt[i]<=MHS)){ContMH<- ContMH+1;}
  if((tt[i]>=VHI) & (tt[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
ConteoC1 <- matrix(0,2,6);
ConteoC1[1,1] <- ContVL
ConteoC1[1,2] <- ContML
ConteoC1[1,3] <- ContM
ConteoC1[1,4] <- ContMH
ConteoC1[1,5] <- ContVH
ConteoC1[1,6] <- sum(Conteo[1,])
ConteoC1[2,1] <- ContVL/N;
ConteoC1[2,2] <- ContML/N;
ConteoC1[2,3] <- ContM/N
ConteoC1[2,4] <- ContMH/N;
ConteoC1[2,5] <- ContVH/N;
ConteoC1[2,6] <- sum(ConteoC1[2,])
colnames(ConteoC1) <- c('VL','ML','M','MH','VH','Ttl')
rownames(ConteoC1) <- c('fr','Prob')
print(ConteoC1)
@


\subsubsection{Bajas, Bajas Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: $C_{2}$}


<<echo = FALSE>>=
datos2   <- dataset %>% filter(dataset$Sequence=='CAACTG'); summary(datos2)
tt <- datos2$tst
summary(tt)
@

<<echo = FALSE>>=
tt1 <- min(tt)
VLI <- tt1
VLS <- CuantilesD[4,1] - 0.0000001
MLI <- CuantilesD[4,1]
MLS <- CuantilesD[1,1] - 0.0000001
MI  <- CuantilesD[1,1]
MS  <- CuantilesD[1,2] - 0.0000001
MHI <- CuantilesD[1,2]
MHS <- CuantilesD[4,2] - 0.0000001
VHI <- CuantilesD[4,2]
VHS <- max(tt)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tt)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tt[i]>=VLI) & (tt[i]<=VLS)){ContVL<- ContVL+1;}
  if((tt[i]>=MLI) & (tt[i]<=MLS)){ContML<- ContML+1;}
  if((tt[i]>=MI)  & (tt[i]<=MS)){ContM <- ContM+1;}
  if((tt[i]>=MHI) & (tt[i]<=MHS)){ContMH<- ContMH+1;}
  if((tt[i]>=VHI) & (tt[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
ConteoC2 <- matrix(0,2,6);
ConteoC2[1,1] <- ContVL
ConteoC2[1,2] <- ContML
ConteoC2[1,3] <- ContM
ConteoC2[1,4] <- ContMH
ConteoC2[1,5] <- ContVH
ConteoC2[1,6] <- sum(Conteo[1,])
ConteoC2[2,1] <- ContVL/N;
ConteoC2[2,2] <- ContML/N;
ConteoC2[2,3] <- ContM/N
ConteoC2[2,4] <- ContMH/N;
ConteoC2[2,5] <- ContVH/N;
ConteoC2[2,6] <- sum(ConteoC2[2,])
colnames(ConteoC2) <- c('VL','ML','M','MH','VH','Ttl')
rownames(ConteoC2) <- c('fr','Prob')
print(ConteoC2)
@


\subsubsection{Bajas, Bajas Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: $C_{3}$}

<<echo = FALSE>>=
### Secuencia TAACGG
datos3   <- dataset %>% filter(dataset$Sequence=='TAACGG'); summary(datos3)
tt <- datos3$tst
summary(tt)
@


<<echo = FALSE>>=
tt1 <- min(tt)
VLI <- tt1
VLS <- CuantilesD[4,1] - 0.0000001
MLI <- CuantilesD[4,1]
MLS <- CuantilesD[1,1] - 0.0000001
MI  <- CuantilesD[1,1]
MS  <- CuantilesD[1,2] - 0.0000001
MHI <- CuantilesD[1,2]
MHS <- CuantilesD[4,2] - 0.0000001
VHI <- CuantilesD[4,2]
VHS <- max(tt)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tt)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tt[i]>=VLI) & (tt[i]<=VLS)){ContVL<- ContVL+1;}
  if((tt[i]>=MLI) & (tt[i]<=MLS)){ContML<- ContML+1;}
  if((tt[i]>=MI)  & (tt[i]<=MS)){ContM <- ContM+1;}
  if((tt[i]>=MHI) & (tt[i]<=MHS)){ContMH<- ContMH+1;}
  if((tt[i]>=VHI) & (tt[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
ConteoC3 <- matrix(0,2,6);
ConteoC3[1,1] <- ContVL
ConteoC3[1,2] <- ContML
ConteoC3[1,3] <- ContM
ConteoC3[1,4] <- ContMH
ConteoC3[1,5] <- ContVH
ConteoC3[1,6] <- sum(Conteo[1,])
ConteoC3[2,1] <- ContVL/N;
ConteoC3[2,2] <- ContML/N;
ConteoC3[2,3] <- ContM/N
ConteoC3[2,4] <- ContMH/N;
ConteoC3[2,5] <- ContVH/N;
ConteoC3[2,6] <- sum(ConteoC3[2,])
colnames(ConteoC3) <- c('VL','ML','M','MH','VH','Ttl')
rownames(ConteoC3) <- c('fr','Prob')
print(ConteoC3)
@



\subsubsection{Bajas, Bajas Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: $C_{4}$}


<<echo = FALSE>>=
### Secuencia TAACTG
datos4   <- dataset %>% filter(dataset$Sequence=='TAACTG'); summary(datos4)
tt <- datos4$tst
summary(tt)
@


<<echo = FALSE>>=
tt1 <- min(tt)
VLI <- tt1
VLS <- CuantilesD[4,1] - 0.0000001
MLI <- CuantilesD[4,1]
MLS <- CuantilesD[1,1] - 0.0000001
MI  <- CuantilesD[1,1]
MS  <- CuantilesD[1,2] - 0.0000001
MHI <- CuantilesD[1,2]
MHS <- CuantilesD[4,2] - 0.0000001
VHI <- CuantilesD[4,2]
VHS <- max(tt)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tt)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tt[i]>=VLI) & (tt[i]<=VLS)){ContVL<- ContVL+1;}
  if((tt[i]>=MLI) & (tt[i]<=MLS)){ContML<- ContML+1;}
  if((tt[i]>=MI)  & (tt[i]<=MS)){ContM <- ContM+1;}
  if((tt[i]>=MHI) & (tt[i]<=MHS)){ContMH<- ContMH+1;}
  if((tt[i]>=VHI) & (tt[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
ConteoC4 <- matrix(0,2,6);
ConteoC4[1,1] <- ContVL
ConteoC4[1,2] <- ContML
ConteoC4[1,3] <- ContM
ConteoC4[1,4] <- ContMH
ConteoC4[1,5] <- ContVH
ConteoC4[1,6] <- sum(Conteo[1,])
ConteoC4[2,1] <- ContVL/N;
ConteoC4[2,2] <- ContML/N;
ConteoC4[2,3] <- ContM/N
ConteoC4[2,4] <- ContMH/N;
ConteoC4[2,5] <- ContVH/N;
ConteoC4[2,6] <- sum(ConteoC4[2,])
colnames(ConteoC4) <- c('VL','ML','M','MH','VH','Ttl')
rownames(ConteoC4) <- c('fr','Prob')
print(ConteoC4)
@



\subsection{Presentacion de resultados}

Es decir las probabilidades condicionales y las probabilidades de cada $C_{i}$ son

<<echo = TRUE>>=
ProbCond <- rbind(ConteoC1[2,],ConteoC2[2,],ConteoC3[2,],ConteoC4[2,])
rownames(ProbCond) <- c('PB_C1','PB_C2','PB_C3','PB_C4')
colnames(ProbCond) <- c('LB','LMB','MB','HMB','HB','Ttl_Prob')
ProbC<- matrix(0,1,4)
ProbC[1] <- PC[[1]]
ProbC[2] <- PC[[2]]
ProbC[3] <- PC[[3]]
ProbC[4] <- PC[[4]]
colnames(ProbC) <- c('C1','C2','C3','C4')
rownames(ProbC) <- c('Prob')
print(ProbC)
print(ProbCond)
@



Por tanto ya podemos determinar las probabiidades $P\left[\cdot|C_{i}\right]P\left[C_{i}\right]$
<<echo = FALSE>>=
print('calcular')
Numeradores <- matrix(0,5,4)
colnames(Numeradores) <- c('C1','C2','C3','C4')
rownames(Numeradores) <- c('LB','LMB','MB','HMB','HB')

Numeradores[1,1] <- ProbCond[1,1]*ProbC[1]
Numeradores[1,2] <- ProbCond[2,1]*ProbC[2]
Numeradores[1,3] <- ProbCond[3,1]*ProbC[3]
Numeradores[1,4] <- ProbCond[4,1]*ProbC[4]

Numeradores[2,1] <- ProbCond[1,2]*ProbC[1]
Numeradores[2,2] <- ProbCond[2,2]*ProbC[2]
Numeradores[2,3] <- ProbCond[3,2]*ProbC[3]
Numeradores[2,4] <- ProbCond[4,2]*ProbC[4]

Numeradores[3,1] <- ProbCond[1,3]*ProbC[1]
Numeradores[3,2] <- ProbCond[2,3]*ProbC[2]
Numeradores[3,3] <- ProbCond[3,3]*ProbC[3]
Numeradores[3,4] <- ProbCond[4,3]*ProbC[4]

Numeradores[4,1] <- ProbCond[1,4]*ProbC[1]
Numeradores[4,2] <- ProbCond[2,4]*ProbC[2]
Numeradores[4,3] <- ProbCond[3,4]*ProbC[3]
Numeradores[4,4] <- ProbCond[4,4]*ProbC[4]

Numeradores[5,1] <- ProbCond[1,5]*ProbC[1]
Numeradores[5,2] <- ProbCond[2,5]*ProbC[2]
Numeradores[5,3] <- ProbCond[3,5]*ProbC[3]
Numeradores[5,4] <- ProbCond[4,5]*ProbC[4]

print(Numeradores)
@


Ahora calculemos $\sum_{i=1}^{4}P\left[\cdot|C_{i}\right]P\left[C_{i}\right]$
<<echo = FALSE>>=
ProbTotal <- matrix(0,5,1)
rownames(ProbTotal) <- c('LB','LMB','MB','HMB','HB')
colnames(ProbTotal) <- c('ProbC')
ProbTotal[1] <- sum(Numeradores[1,])
ProbTotal[2] <- sum(Numeradores[2,])
ProbTotal[3] <- sum(Numeradores[3,])
ProbTotal[4] <- sum(Numeradores[4,])
ProbTotal[5] <- sum(Numeradores[5,])
print(ProbTotal)
@

para finalmente obtener $P\left[C_{i}|\cdot\right]= \frac{P\left[\cdot|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[\cdot|C_{i}\right]P\left[C_{i}\right]}$

<<echo = FALSE>>=
ProbCi_B <- matrix(0,5,4)
rownames(ProbCi_B) <- c('LB','LMB','MB','HMB','HB')
colnames(ProbCi_B) <- c('C1','C2','C3','C4')

ProbCi_B[1,1] <- Numeradores[1,1]/ProbTotal[1]
ProbCi_B[1,2] <- Numeradores[1,2]/ProbTotal[1]
ProbCi_B[1,3] <- Numeradores[1,3]/ProbTotal[1]
ProbCi_B[1,4] <- Numeradores[1,4]/ProbTotal[1]

ProbCi_B[2,1] <- Numeradores[2,1]/ProbTotal[2]
ProbCi_B[2,2] <- Numeradores[2,2]/ProbTotal[2]
ProbCi_B[2,3] <- Numeradores[2,3]/ProbTotal[2]
ProbCi_B[2,4] <- Numeradores[2,4]/ProbTotal[2]

ProbCi_B[3,1] <- Numeradores[3,1]/ProbTotal[3]
ProbCi_B[3,2] <- Numeradores[3,2]/ProbTotal[3]
ProbCi_B[3,3] <- Numeradores[3,3]/ProbTotal[3]
ProbCi_B[3,4] <- Numeradores[3,4]/ProbTotal[3]

ProbCi_B[4,1] <- Numeradores[4,1]/ProbTotal[4]
ProbCi_B[4,2] <- Numeradores[4,2]/ProbTotal[4]
ProbCi_B[4,3] <- Numeradores[4,3]/ProbTotal[4]
ProbCi_B[4,4] <- Numeradores[4,4]/ProbTotal[4]

ProbCi_B[5,1] <- Numeradores[5,1]/ProbTotal[5]
ProbCi_B[5,2] <- Numeradores[5,2]/ProbTotal[5]
ProbCi_B[5,3] <- Numeradores[5,3]/ProbTotal[5]
ProbCi_B[5,4] <- Numeradores[5,4]/ProbTotal[5]

ProbM <- ProbCi_B
print(ProbM)
@




\subsection{Tablas}

\begin{table}[h!]
\begin{center}
\scalebox{0.85}{\begin{tabular}{|l||cccc|}\hline\hline
\multirow{2}{*}{Time} & \multicolumn{4}{c|}{Propuesta 1}\\ 
& $C_{1}$&$C_{2}$&$C_{3}$& $C_{4}$\\\hline\hline
$P\left[LB|C_{i}\right]$&0.02702703&0.01015228&0.01923077&0.03685504\\
$P\left[LMB|C_{i}\right]$&0.02702703&0.3553299&0.09615385&0.05896806\\
$P\left[MB|C_{i}\right]$&0.7027027&0.7005076&0.5192308&0.6388206\\
$P\left[HMB|C_{i}\right]$&0.1351351&0.1065990&0.1538462&0.1253071\\
$P\left[HB|C_{i}\right]$&0.1081081&0.1472081&0.2115385&0.1400491\\\hline\hline
$P\left[C_{i}\right]$&0.05339105&0.28427128&0.07503608&0.058730159\\\hline\hline
$P\left[LB|C_{i}\right]P\left[C_{i}\right]$&0.001443001&0.002886003&0.001443001&0.02164502\\
$P\left[LMB|C_{i}\right]P\left[C_{i}\right]$&0.001443001&0.010101010&0.007215007&0.03463203\\
$P\left[MB|C_{i}\right]P\left[C_{i}\right]$&0.037518038&0.199123199&0.038961039&0.37518038\\
$P\left[HMB|C_{i}\right]P\left[C_{i}\right]$&0.007215007&0.030303030&0.011544112&0.07359307\\
$P\left[HB|C_{i}\right]P\left[C_{i}\right]$&0.005772006&0.041847042&0.015873016&0.14004891\\\hline\hline
$\sum_{i=1}^{4}P\left[LB|C_{i}\right]P\left[C_{i}\right]$&0.02741703&&&\\
$\sum_{i=1}^{4}P\left[LMB|C_{i}\right]P\left[C_{i}\right]$&0.05339105&&&\\
$\sum_{i=1}^{4}P\left[MB|C_{i}\right]P\left[C_{i}\right]$&0.65079365&&&\\
$\sum_{i=1}^{4}P\left[HMB|C_{i}\right]P\left[C_{i}\right]$&0.12265512&&&\\
$\sum_{i=1}^{4}P\left[HB|C_{i}\right]P\left[C_{i}\right]$&0.14574315&&&\\\hline\hline
$P\left[C_{i}|LB\right]=\frac{P\left[LB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[LB|C_{i}\right]P\left[C_{i}\right]}$&0.05263158&0.1052632&0.05263158&0.7894737\\
$P\left[C_{i}|LMB\right]=\frac{P\left[LMB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[LMB|C_{i}\right]P\left[C_{i}\right]}$&0.027027003&0.1891892&0.13513514&0.6486486\\
$P\left[C_{i}|MB\right]=\frac{P\left[MB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[MB|C_{i}\right]P\left[C_{i}\right]}$&0.05764967&0.3059867&0.05986696&0.5764967\\
$P\left[C_{i}|HMB\right]=\frac{P\left[HMB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[HMB|C_{i}\right]P\left[C_{i}\right]}$&0.05882353&0.2470588&0.09411765&0.6000000\\
$P\left[C_{i}|HB\right]=\frac{P\left[HB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[HB|C_{i}\right]P\left[C_{i}\right]}$&0.03960396&0.2871287&0.10891089&0.5643564\\\hline\hline
\end{tabular}}
\caption{Probabilidades Condicionales Modelo 1}
\label{tab:Simulation.Results}
\end{center}
\end{table}











\section{Pendientes}

\begin{itemize}
\item Incluir una nueva categor\'ia para valores moderados, el \'area gris del art\'iculo: Moderate

\item Lista de genes por las categor\'ias: muy bajo, moderadamente bajos, moderados, moderadamente altos y muy altos.
\item dado el valor de un gen determinar en qu\'e categor\'ia est\'a: LB,MLB,MB,HMB,HB.


\end{itemize}

\subsection*{Expresion Basal Muy Baja}


<<echo = FALSE>>=
### Secuencia TAACGG
EBVL   <- dataset %>% filter(dataset$tst>=VLI & dataset$tst<=VLS); 
ExpBasalVL <- EBVL[,c('Gen_Id','Sequence','Position','BasalExp','tst')]
colnames(ExpBasalVL) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalVL,"ExpBasalMuyBaja.csv")
summary(ExpBasalVL)
@

\subsection*{Expresion Basal Moderada Baja}

<<echo = FALSE>>=
EBML   <- dataset %>% filter(dataset$tst>=MLI & dataset$tst<=MLS); 
ExpBasalML <- EBML[,c('Gen_Id','Sequence','Position','BasalExp','tst')]
colnames(ExpBasalML) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalML,"ExpBasalModBaja.csv")
summary(ExpBasalML)
@

\subsection*{Expresion Basal Moderada}

<<echo = FALSE>>=
EBM   <- dataset %>% filter(dataset$tst>=MI & dataset$tst<=MS); 
ExpBasalM <- EBM[,c('Gen_Id','Sequence','Position','BasalExp','tst')]
colnames(ExpBasalM) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalM,"ExpBasalModerada.csv")
summary(ExpBasalM)
@

\subsection*{Expresion Basal Moderada Alta}

<<echo = FALSE>>=
EBMH   <- dataset %>% filter(dataset$tst>=MHI & dataset$tst<=MHS); 
ExpBasalMH <- EBMH[,c('Gen_Id','Sequence','Position','BasalExp','tst')]
colnames(ExpBasalMH) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalMH,"ExpBasalModAlta.csv")
summary(ExpBasalMH)
@

\subsection*{Expresion Basal Muy Alta}
<<echo = FALSE>>=
EBVH   <- dataset %>% filter(dataset$tst>=VHI & dataset$tst<=VHS); 
ExpBasalVH <- EBVH[,c('Gen_Id','Sequence','Position','BasalExp','tst')]
colnames(ExpBasalVH) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalVH,"ExpBasalMuyAlta.csv")
summary(ExpBasalVH)
@


\section{Pendientes}

\begin{itemize}
\item Incluir una nueva categor\'ia para valores moderados, el \'area gris del art\'iculo: Moderate, \textbf{ATENDIDA}

\item Lista de genes por las categor\'ias: muy bajo, moderadamente bajos, moderadamente altos y muy altos, \textbf{ATENDIDA}
\item dado el valor de un gen determinar en qu\'e categor\'ia est\'a: LB,MLB,HMB,HB.
\item Se va a utilizar el Modelo 2, \textbf{ATENDIDA}

\item Incluir 

\end{itemize}


\section{Respondiendo Pregunta abierta}

Recordemos que se considera una partici\'on para el dominio de las \textit{Expresiones Basales}: $Y=\left\{y_{1},y_{2},\ldots,y_{n}\right\}$, y una partici\'on para el dominio de las posiciones de los genes: $X=\left\{x_{1},x_{2},\ldots,x_{m}\right\}$. Adem\'as se tienen cuatro clases $\left\{C_{1},C_{2},C_{3},C_{4}\right\}$, estas clases corresponden a los motifs: $\left\{CAACGG,CAACTG,TAACGG,TAACTG\right\}$ respectivamente.

Recordemos que para cada elemento de $Y$ es posible determina la Probabilidad de pertenecer a una determinada clase dependiendo de su expresi\'on basal por medio de la ecuaci\'on:

\begin{eqnarray}\label{Eq.BasalClase2}
P\left[\textrm{pertenecer a la clase }C_{i}| y_{k}\right]=\frac{P\left[y_{k}|C_{i}\right]P\left[C_{i}\right]}{\sum_{k=1}^{n}P\left[y_{k}|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}
para $k=1,2,\ldots,n$, donde las clases corresponden a los 4 diferentes motif's que se tienen.

La probabilidad de que una expresi\'on basal pertenezca a algunas de las clases: (Muy baja, Moderadamente Baja, Moderada, Moderadamente Alta, Muy Alta) son 

<<echo = FALSE>>=
print(ProbClEB)
@

es decir

\begin{table}[h!]
\begin{center}
\scalebox{0.85}{\begin{tabular}{|l||ccccc|}\hline\hline
& $VL$& $ML$&$M$&$MH$& $VH$\\\hline\hline
$Prob\left[\cdot\right]$&0.02741703&0.05339105&0.6507937&0.1226551&0.1457431\\\hline\hline
\end{tabular}}
\caption{Probabilidades Expresion Basal por categor\'ia}
\label{tab:Simulation.Results2}
\end{center}
\end{table}


\section{Pregunta Pendiente}

Ahora lo que se va a hacer, es para cada categor\'ia de las expresiones basales se va a determinar la Probabilidad de que un determinado gen pertenezca a una de las categore\'ias asumiendo una distribuci\'on weibull, y considerando los datos contenidos en cada categor\'ia:

La lista de genes por determinar su clasificación con respecto a la expresión Basal dada su posici\'on es 

Recoredmos que se comienza con las Expresiones basales:
<<echo = FALSE>>=
summary(BE)
mBE <- mean(BE); print(mBE)
deBE <- sd(BE); print(deBE)
@
Luego son normalizados

<<echo = FALSE>>=
NormBE <- (BE-mBE)/deBE;
summary(NormBE)
@

Para finalmente ser transformados por medio del $Log_{2}$

<<echo = FALSE>>=
summary(Log2BE)
print(mean(Log2BE))
print(sd(Log2BE))
@

Entonces, la nueva lista de genes a clasificar son:
<<echo = FALSE>>=
GeneList <- matrix(0,8,2)
GeneList[1] <- 24.98;
GeneList[2] <- 36.83;
GeneList[3] <- 19.68;
GeneList[4] <- 17.35;
GeneList[5] <- 22.77;
GeneList[6] <- 7.34;
GeneList[7] <- 59.48;
GeneList[8] <- 5.99;
@

estas expresiones basales deben ser normalizadas y log2- transformadas con los par\'ametros de la muestra, $\overline{X}_{Log_{2}}$ y $S_{Log_{2}}$, es decir, se supone que provienen de la misma muestra y por tanto tienen la misma media y la misma desviaci\'on est\'andar, por tanto se normalizan y luego se les aplica $log_{2}$, resultando los siguientes valores.

<<echo = FALSE>>=
GeneList[,2] <- log2(GeneList[,1]-mean(Log2BE))/sd(Log2BE)
rownames(GeneList) <- c('EHI_000550','EHI_008130',
                        'EHI_012420','EHI_063550',
                        'EHI_092160','EHI_092700',
                        'EHI_129790','EHI_136420')
print(GeneList)
listagenes <- as.numeric(GeneList[,2])
#print(listagenes)
@

Ahora, la clasificación se hace determinando la clase que maximiza la probabilidad: $P\left[y_{k}|EB\right]*P\left[EB\right]$, estos valores son los que vamos denominar, temporalmente como verosimilitud, entonces, determinamos estos valores para cada intervalo de las Expresiones Basales: Muy baja (VL), Moderadamente Baja (ML), Moderada (M), Moderadamente Alta (MH) y Muy Alta (VH).


\subsection{EXPRESION BASAL MUY BAJA}
Para este rango de valores los resultados obtenidos son:

<<echo = FALSE>>=¨
#summary(ExpBasalVL)
t1         <- ExpBasalVL$NormLog2Basal; n1 <- length(t1);
ProbEBVL   <-  n1/nBE;
meanEBVL   <- mean(t1);# print(meanEBVL)
stdDevEBVL <- sd(t1); #  print(stdDevEBVL)
ProbVL     <- matrix(0,8,3)
ProbVL[,1] <- dnorm(listagenes, mean = meanEBVL, sd = stdDevEBVL)
ProbVL[,2] <- pnorm(listagenes,   mean = meanEBVL, sd = stdDevEBVL)
ProbVL[,3] <- as.numeric(ProbVL[,2])*ProbEBVL
ProbVL     <- cbind(GeneList[,2],ProbVL)
colnames(ProbVL) <- c('NormLog2BE','dnorm','pnorm','ProbCy')
print(ProbVL)
@

\subsection{EXPRESION BASAL MODERADAMENTE BAJA}

Para el rango de valores correspondientes a Moderadamente Baja, los resultados obtenidos son:

<<echo = FALSE>>=
#summary(ExpBasalML)
t2         <- ExpBasalML$NormLog2Basal; n2 <- length(t2)
ProbEBML   <-  n2/nBE;
meanEBML   <- mean(t2); #print(meanEBML)
stdDevEBML <- sd(t2);   #print(stdDevEBML)
ProbML     <- matrix(0,8,3)
ProbML[,1] <- dnorm(listagenes, mean = meanEBML, sd = stdDevEBML)
ProbML[,2] <- pnorm(listagenes,   mean = meanEBML, sd = stdDevEBML)
ProbML[,3] <- as.numeric(ProbML[,2])*ProbEBML
ProbML     <- cbind(GeneList[,2],ProbML)
colnames(ProbML) <- c('NormLog2BE','dnorm','pnorm','ProbCy')
print(ProbML)
@

\subsection{EXPRESION BASAL MODERADA}

Mientras que para el rango de valores correspondiente a Expresi\'on Basal Moderada, se obtuvo:

<<echo = FALSE>>=
#summary(ExpBasalM)
t3        <- ExpBasalM$NormLog2Basal; n3 <- length(t3)
ProbEBM   <-  n3/nBE;
meanEBM   <- mean(t3); #print(meanEBM)
stdDevEBM <- sd(t3);   #print(stdDevEBM)
ProbM     <- matrix(0,8,3)
ProbM[,1] <- dnorm(listagenes, mean = meanEBM, sd = stdDevEBM)
ProbM[,2] <- pnorm(listagenes,   mean = meanEBM, sd = stdDevEBM)
ProbM[,3] <- as.numeric(ProbM[,2])*ProbEBM
ProbM     <- cbind(GeneList[,2],ProbM)
colnames(ProbM) <- c('NormLog2BE','dnorm','pnorm','ProbCy')
print(ProbM)
@

\subsection{EXPRESION BASAL MODERADAMENTE ALTA}

Para el rango de Expresi\'on Basal Moderadamente Alta:

<<echo = FALSE>>=
#summary(ExpBasalMH)
t4         <- ExpBasalMH$NormLog2Basal; n4 <- length(t4)
ProbEBMH   <-  n4/nBE;
meanEBMH   <- mean(t4); #print(meanEBMH)
stdDevEBMH <- sd(t4);   #print(stdDevEBMH)
ProbMH     <- matrix(0,8,3)
ProbMH[,1] <- dnorm(listagenes, mean = meanEBMH, sd = stdDevEBMH)
ProbMH[,2] <- pnorm(listagenes,   mean = meanEBMH, sd = stdDevEBMH)
ProbMH[,3] <- as.numeric(ProbMH[,2])*ProbEBMH
ProbMH     <- cbind(GeneList[,2],ProbMH)
colnames(ProbMH) <- c('NormLog2BE','dnorm','pnorm','ProbCy')
print(ProbMH)
@

\subsection{EXPRESION BASAL MUY ALTA}
Finalmente, para el rango de valores correspondientes a la Expresi\'on Basal Muy Alta se tiene: 

<<echo = FALSE>>=
#summary(ExpBasalVH)
t5         <- ExpBasalVH$NormLog2Basal; n5 <- length(t5)
ProbEBVH   <-  n5/nBE;
meanEBVH   <- mean(t5); #print(meanEBVH)
stdDevEBVH <- sd(t5);   #print(stdDevEBVH)
ProbVH     <- matrix(0,8,3)
ProbVH[,1] <- dnorm(listagenes, mean = meanEBVH, sd = stdDevEBVH)
ProbVH[,2] <- pnorm(listagenes,   mean = meanEBVH, sd = stdDevEBVH)
ProbVH[,3] <- as.numeric(ProbMH[,2])*ProbEBVH
ProbVH     <- cbind(GeneList[,2],ProbVH)
colnames(ProbVH) <- c('NormLog2BE','dnorm','pnorm','ProbCy')
print(ProbVH)
@


\subsection{Resultados}

De lo anterior se tiene la siguiente informaci\'on conjunta con fines comparativos
<<echo = FALSE>>=
ProbClassgivenGen <- cbind(GeneList,
                           as.numeric(ProbVL[,2]),
                           as.numeric(ProbVL[,4]),
                           as.numeric(ProbML[,2]),
                           as.numeric(ProbML[,4]),
                           as.numeric(ProbM[,2]),
                           as.numeric(ProbM[,4]),
                           as.numeric(ProbMH[,2]),
                           as.numeric(ProbMH[,4]),
                           as.numeric(ProbVH[,2]),
                           as.numeric(ProbVH[,4]))
row.names(ProbClassgivenGen) <- c('EHI_000550',
                                 'EHI_008130',
                                 'EHI_012420',
                                 'EHI_063550',
                                 'EHI_092160',
                                 'EHI_092700',
                                 'EHI_129790',
                                 'EHI_136420')
colnames(ProbClassgivenGen) <- c('ExpBasal',
                                 'Log2NormExpBasal',
                                 'dnorm_VL','LikelihoodVL',
                                 'dnorm_ML','LikelihoodML',
                                 'dnorm_M','LikelihoodM',
                                 'dnorm_MH','LikelihoodMH',
                                 'dnorm_VH','LikelihoodVH')
print(ProbClassgivenGen)

@

misma que para facilitar su lectura se puede ver como
<<echo = FALSE>>=
cols1 <- c(1:4);       NewGenes1 <- ProbClassgivenGen[,cols1]; print(NewGenes1)
cols2 <- c(1:2,5:6);   NewGenes2 <- ProbClassgivenGen[,cols2]; print(NewGenes2)
cols3 <- c(1:2,7:8);   NewGenes3 <- ProbClassgivenGen[,cols3]; print(NewGenes3)
cols4 <- c(1:2,9:10);  NewGenes4 <- ProbClassgivenGen[,cols4]; print(NewGenes4)
cols5 <- c(1:2,11:12); NewGenes5 <- ProbClassgivenGen[,cols5]; print(NewGenes5)

@

Por lo tanto, se puede asegurar que la nueva lista de genes pertenecen a la clase de Expresi\'on Basal Moderada.


\section{Notas y observaciones}
\begin{itemize}
\item[I. ] En versiones anteriores se lleg\'o a la conclusi\'on de que la distribuci\'on que mejor ajustaba a los datos es una \textit{distribuci\'on Weibull}, y con base en esta aseveraci\'on para la \textit{Expresi\'on Basal} se construyeron los intervalos correspondientes a \textit{muy baja, moderadamente baja, moderada, moderadamente alta, muy alta} para posteriormente determinar las probabilidades ilustradas en la tabla \ref{tab:Simulation.Results}; con esta informaci\'on se atendieron a las preguntas elaboradas en la secci\'on \textbf{3.4 Preguntas abiertas}, y posteriormente lo se\~nalado en la secci\'on \textbf{5. Pendientes}, con lo cual se corrobor\'o que ajustar una distribuci\'on weibull a los datos es la mejor elecci\'on.


\item[II. ] Al comenzar a atender la pregunta abierta: dado el valor de la expresi\'on basal de un gen determinar en que rango de valores corresponde, era necesario determinar la probabilidad de ocurrencia del gen, dado el rango de valores. Para poder hacer esto por medio del programa $R$-statistics con la funci\'on dweibull se requer\'ia determinar los par\'ametros de forma y escala con base en los subconjuntos de datos para cada rango. Despu\'es de hacer una b\'usqueda en la red sobre las posibles formas de calcularlos, no se obtuvieron resultados favorables, 

\item[III. ] Derivado de lo anterior y despu\'es de revisar nuevamente la teor\'ia y metodolog\'ia para implementar favorablemente el \textbf{m\'etodo de clasificaci\'on por Naive Bayes}, calcular las probabilidades se\~naladas en el n\'umero anterior es posible llevarlas a cabo asumiendo que los datos se distribuyen de manera normal. Por tanto se revisaron nuevamente los ajustes realizados, la distribuci\'on normal s\'i se ajusta a los datos, con problemas con las colas, o valores extremos, pero en general se puede decir que s\'i ajusta los datos, pero \textit{no es el mejor}. 

\item[IV. ] Entonces, esta versi\'on de reporte se hace considerando que los datos se ajustan a una distribuci\'on normal, se determina que los rangos para las expresiones basales son las correspondientes all $65\%$ y $80\%$ con intervalos, con los cuantiles determinados con base en los datos, y no en el ajuste:
\begin{itemize}
\item Very Low Expression: $\left[-\infty,-0.53752025\right)$,
\item Moderately Low Expression: $\left[-0.537552025,0.13093097\right)$,
\item Moderate Expresion: $\left[0.13093097,4.528913\right)$,
\item Moderately High Expression: $\left[4.528913,5.969012\right)$,
\item Very High Expression: $\left[5.969012,\infty\right)$.
\end{itemize}
y su gr\'afico correspondiente: 

<<echo = FALSE, fig=TRUE>>=
hist(tst, breaks = nbreaks, col= rainbow(15,0.7), xlim=c(-3,15),
     main = 'Log2 Transformed Basal Expresion - DATA', lty=9)
#===========================================================================
abline(v=CuantilesD[1,1], lty=2, col="darkgoldenrod4"); # 65% INFERIOR
abline(v=CuantilesD[1,2], lty=2, col="darkgoldenrod4"); # 65% SUPERIOR
#abline(v=CuantilesD[2,1], lty=2, col="darkblue");  # 70% INFERIOR
#abline(v=CuantilesD[2,2], lty=2, col="darkblue"); # 70% SUPERIOR
#abline(v=CuantilesD[3,1], lty=2, col="aquamarine4");  # 75% INFERIOR
#abline(v=CuantilesD[3,2], lty=2, col="aquamarine4"); # 75% SUPERIOR
abline(v=CuantilesD[4,1], lty=2, col="green");  # 80% INFERIOR
abline(v=CuantilesD[4,2], lty=2, col="green"); # 80% SUPERIOR
#abline(v=CuantilesD[5,1], lty=2, col="brown");  # 85% INFERIOR
#abline(v=CuantilesD[5,2], lty=2, col="brown"); # 85% SUPERIOR
#abline(v=CuantilesD[6,1], lty=2, col="red");  # 90% INFERIOR
#abline(v=CuantilesD[6,2], lty=2, col="red"); # 90% SUPERIOR
#abline(v=CuantilesD[7,1], lty=2, col="blue");  # 95% INFERIOR
#abline(v=CuantilesD[7,2], lty=2, col="blue"); # 95% SUPERIOR
#abline(v=CuantilesD[8,1], lty=2, col="orange");  # 99% INFERIOR
#abline(v=CuantilesD[8,2], lty=2, col="orange"); # 99% SUPERIOR
legend("topright",
       legend=c("65%","80%"), 
       pch=c(1,2),
       col=c("darkgoldenrod4","green"))
@

\item[V. ] Con lo descrito hasta ahora se realizan los c\'alculo y se obtiene que

<<echo = FALSE>>=
print(NewGenes3)
@
\end{itemize}
es la clase que maximiza la probabilidad.

Finalmente, quiz\'a lo que falta de atender es 
\begin{itemize}
\item[a) ] para la nueva lista de genes, determinar a qu\'e motif pertenece.

\item[b) ] lo correspondiente a las posiciones de los genes.

\end{itemize}









\end{document}