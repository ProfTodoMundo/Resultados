\documentclass[12pt]{article}         % the type of document and font size (default 10pt)
\usepackage[margin=1.0in]{geometry}   % sets all margins to 1in, can be changed
\usepackage{moreverb}                 % for verbatimtabinput -- LaTeX environment
\usepackage{rotating}
\usepackage{url}     
\usepackage{hyperref}
% for \url{} command
\usepackage{amssymb}                  % for many mathematical symbols
\usepackage[pdftex]{lscape}           % for landscaped tables
\usepackage{longtable}
\usepackage[dvipsnames]{xcolor}
\usepackage{multicol,multirow}
\usepackage{tikz}
% for tables that break over multiple pages
\title{Aplicacion Naive Bayes}  % to specify title
\author{$\blacktriangleright\because\therefore\because\therefore\because\therefore\because\therefore\because\therefore\because\therefore\because\therefore\because\therefore\because\blacktriangleleft$}          % to specify author(s)
\begin{document}                      % document begins here
\SweaveOpts{concordance=TRUE}

% If .nw file contains graphs: To specify that EPS/#pdf graph files are to be 
% saved to 'graphics' sub-folder
%     NOTE: 'graphics' sub-folder must exist prior to Sweave step
%\SweaveOpts{prefix.string=graphics/plot}

% If .nw file contains graphs: to modify (shrink/enlarge} size of graphics 
% file inserted
%         NOTE: can be specified/modified before any graph chunk
\setkeys{Gin}{width=1.0\textwidth}

\maketitle              % makes the title
\tableofcontents        % inserts TOC (section, sub-section, etc numbers and titles)
%\listoftables           % inserts LOT (numbers and captions)
%\listoffigures          % inserts LOF (numbers and captions)
%                        %     NOTE: graph chunk must be wrapped with \begin{figure}, 
%                        %  \end{figure}, and \caption{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Where everything else goes
%===================================================================================
\section{Lectura de las Bases de Datos}
Se cargan las librearias necesarias para poder procesar y sistematizar las bases de datos

<<echo = FALSE>>=
#===========================================================================
setwd("~/Desktop/Datos Elisa")
#===========================================================================
library(ggplot2);   library(dplyr);         library(readxl);
library(pastecs);   library(sciplot);       library(MASS);
library(gridExtra); library("gplots");      library("lattice");
library(car);       library(gridExtra);     library(lattice);
library(corrplot);  library(readr);         library(readxl);   
library(rvest);     library(RSQLite);       library(DBI);    
library(xml2);      library(RCurl);         library(devtools);
library(ggplot2);   library(datasets);      library(dplyr);
library(sciplot);   library(scatterplot3d); library("car")
library(psych);     library("gplots");      library("plotrix")
library(gplots);    library(moments);       library(univariateML)
#===========================================================================
dataset1 <- read_excel("BDD_Definitiva.xlsx")
dataset <- na.omit(dataset1)
@


<<echo = FALSE>>=
dataset$Secuencia = factor(dataset$Secuencia,
                           levels = c('CAACGG','CAACTG','TAACGG','TAACTG'),
                           labels = c('CAACGG','CAACTG','TAACGG','TAACTG'))
colnames(dataset) <- c('Sequence', 'Position', 'Gen_Id1','Gen_Id2', 
                       'Description', 'BasalExp','DigitVerif')
#===========================================================================
datosn <- dataset$Position;
d <- as.numeric(datosn);
dataset$Position <- d
#===========================================================================
#summary(dataset)
#===========================================================================
@

<<echo = FALSE>>=
dataset$DigitVerif <- dataset$Sequence
dataset$DigitVerif = factor(dataset$DigitVerif,
                            levels = c('CAACGG','CAACTG','TAACGG','TAACTG'),
                            labels = c(1,2,3,4))
#===========================================================================
#summary(dataset)
#View(dataset)
#===========================================================================
@

<<echo = FALSE>>=
CtoDatos <- dataset[,c('Sequence','DigitVerif','Position','BasalExp','Gen_Id1')]
colnames(CtoDatos) <- c('Sequence','CodedSeq','Position','BasalExp','Gen_Id')
#View(CtoDatos)
#summary(CtoDatos)
bdd <- CtoDatos
#===========================================================================
nbreaks <- 80
#===========================================================================
@





<<echo = FALSE, fig=TRUE>>=
tP <- hist(bdd$Position, breaks = nbreaks, col= rainbow(15,0.7), main = 'Position')
#print(tP)
@


<<echo = FALSE, fig=FALSE>>=
tBE <- hist(bdd$BasalExp, breaks = nbreaks, col= rainbow(15,0.7), main = 'BasalExpresion')
#print(tBE)
@

Conteo de datos por Clase

<<echo = FALSE>>=
counts<- table(bdd$Sequence)
t <- table(bdd$Sequence)
prop.table(t)*100
@



<<echo = FALSE>>=
LF <- bdd$Position
#summary(LF)
hist(LF, breaks = nbreaks,col= rainbow(15,0.7), main = 'Raw Position' )
CLF <- -LF
@


Posici\'on normalizada

<<echo = FALSE>>=
m1 <- 0; #mean(CLF)
de1 <- sd(CLF)
NormPosition <- (CLF-m1)/de1
tNP <- hist(NormPosition, breaks = nbreaks, col= rainbow(15,0.7), main = ' Estandarized Position')
summary(NormPosition)
#print(tNP)
@

$Log_{2}$ Posici\'on Normalizada

<<echo = FALSE, fig=TRUE>>=
Log2NP <- log2(NormPosition)
summary(Log2NP)
tLNP <- hist(Log2NP, breaks = nbreaks, col= rainbow(15,0.7), main = ' Log2 Transformed Position')
#print(tLNP)
@


<<echo = FALSE, fig=FALSE>>=
tLNP <- hist(Log2NP, breaks = nbreaks)
#print(tLNP)
@


<<echo = FALSE>>=
ProbsNP <- tLNP$counts/sum(tLNP$counts)
#print(ProbsNP)
@

$Log_{2}$ Expresi\'on Basal Normalizada

<<echo = FALSE, fig=FALSE>>=
BE <- bdd$BasalExp
hist(BE,breaks = nbreaks, col= rainbow(6,0.7), main = 'Raw Basal Expresion' )
#summary(BE)
@


<<echo = FALSE>>=
mBE <- mean(BE)
deBE <- sd(BE)
NormBE <- (BE-mBE)/deBE
@


<<echo = FALSE, fig=FALSE>>=
# Normalizados
hist(NormBE, breaks = nbreaks, col= rainbow(15,0.7), main = ' Estandarized Basal Expresion')
#summary(NormBE)
@


<<echo = FALSE, fig=TRUE>>=
# Aplicando Log2
Log2BE <- log2(BE)
#summary(Log2BE)
hist(Log2BE, breaks = nbreaks, col= rainbow(15,0.7), main = ' Log2 Transformed Basal Expresion')
@


<<echo = FALSE, fig=FALSE>>=
tL2BE <- hist(Log2BE, breaks = nbreaks)
#print(tL2BE)
@


<<echo = FALSE>>=
ProbsLog2BE <- tL2BE$counts/sum(tL2BE$counts)
#print(ProbsLog2BE)
@


\section{ Ajustando Modelos}

<<echo = FALSE, fig=TRUE>>=
#===========================================================================
library("fitdistrplus"); library("MASS"); library("survival")
boxplot(Log2BE, main = 'Log2BE' )
@


<<echo = FALSE, fig= true>>=
tst<- Log2BE
boxplot(tst, main = 'Translated Log2BE')
summary(tst)
hist(tst, breaks = nbreaks, col= rainbow(15,0.7), main = 'Log2 Transformed Basal Expresion')
#===========================================================================
@


<<echo = FALSE, fig=TRUE>>=
plotdist(tst, histo = TRUE, demp = TRUE)
descdist(tst)
#===========================================================================
@

\subsection{ Ajustando una Distribucion Normal}

<<echo = FALSE>>=
#===========================================================================
fw5<-fitdist(tst, "norm")
summary(fw5)
@


<<echo = FALSE, fig=TRUE>>=
denscomp(fw5)
@


<<echo = FALSE, fig=TRUE>>=
cdfcomp(fw5)
@


<<echo = FALSE, fig=TRUE>>=
qqcomp(fw5)
@


<<echo = FALSE, fig=TRUE>>=
ppcomp(fw5)
@


Los resultados del ajuste son: 

<<echo = FALSE>>=
summary(fw5)
@

<<echo = FALSE>>=
quantile(fw5, probs = 0.05)
@

<<echo = FALSE>>=
quantile(tst, probs = 0.05)
@


<<echo = FALSE>>=
dist1 <- mlnorm(x=tst)
summary(dist1)
@


<<echo = FALSE>>=
vals <- fw5$estimate
Media <- as.numeric(vals[1])
SDev <- as.numeric(vals[2])
@




\subsection{Asumiendo una distribuci\'on Weibull}

Recordemos que se traslado una unidad para que los datos fuesen positivos y asÃ­ poder
ajustar una distribuci\'on, la mejor distribuci\'on que se ajusta a los datos trasladados una unidad es la \textit{weibull}

<<echo = FALSE>>=
tt<- Log2BE+1
summary(tt)
@


<<echo = FALSE, fig=TRUE>>=
boxplot(tt, main = 'Translated Log2BE')
@


<<echo = FALSE, fig=TRUE>>=
hist(tt, breaks = nbreaks, col= rainbow(15,0.7), main = 'Translated Log2 Transformed Basal Expresion')
#===========================================================================
@

Se grafica la funci\'on de distribuci\'on emp\'irica, junto con su funci\'on de distribuci\'on de probabilidad acumulada

<<echo = FALSE, fig=TRUE>>=
xt<- plotdist(tt, histo = TRUE, demp = TRUE)
descdist(tt)
#===========================================================================
@

comparaci\'on de probables distribuciones que se ajustan a los datos, con base en el sesgo y la kurtosis.


<<echo = FALSE, fig=TRUE>>=
descdist(tt)
#===========================================================================
@

En esta parte se ajusta una distribuci\'on weibull
<<echo = FALSE>>=
#===========================================================================
fw3<-fitdist(tt, "weibull")
summary(fw3)
@

Se muestra el histograma y la curva de ajuste

<<echo = FALSE, fig=TRUE>>=
denscomp(fw3)
@

Ahora la distribuci\'on acumulada

<<echo = FALSE, fig=TRUE>>=
cdfcomp(fw3)
@

El gr\'afico QQ-plot cumprueba si dos muestras provienene de la misma distribuci\'on, en caso de que provengan de la misma distribuci\'on, los puntos aparecer\'an alineados a la recta.
<<echo = FALSE, fig=TRUE>>=
qqcomp(fw3)
@

La gr\'afica de las funciones de distribuci\'on acumulada de los resicuales, si los residuales estandarizados se distribuyen de acuerdo a la distribuci\'on propuesta, los puntos deber\'an de acercarse o ajustarse a la l\'inea recta $y=x$

<<echo = FALSE, fig=TRUE>>=
ppcomp(fw3)
@

Finalmentes se obtienen los intervalos de confianza para los par\'ametros de la distribuci\'on propuesta, en el caso de la Waibull son los par\'ametros de forma y de escala.

<<echo = FALSE>>=
confint(fw3)
@

\subsection{Cuantiles}

Los datos del art\'iculo principal son sim\'etricos y se distribuyen normal casi perfectamente, con lo que es relativamente m\'as sencillo determinar los valores que ser\'an considerados de frecuencias bajas, medias y altas. Para nuestro caso la distribuci\'on emp\'irica es asim\'etrica, por eso no es posible replicar los mismos criterios.



<<echo = FALSE>>=
#quantile(fw3, probs = 0.005)
qadj005 <- quantile(fw3, probs = 0.005)
t <- qadj005[[1]]
qadj005 <-  t[[1]]

qdat005 <- quantile(tt, probs = 0.005)
t <- qdat005[[1]]
qdat005 <- t


qadj995 <- quantile(fw3, probs = 0.995)
t <- qadj995[[1]]
qadj995 <-  t[[1]]

qdat995 <- quantile(tt, probs = 0.995)
quantile(tt, probs = 0.995)
t <- qdat995[[1]]
qdat995 <- t

quantile(fw3, probs = 0.025)
qadj025 <- quantile(fw3, probs = 0.025)
t <- qadj025[[1]]
qadj025 <-  t[[1]]

qdat025 <- quantile(tt, probs = 0.025)
t <- qdat025[[1]]
qdat025 <- t


qadj975 <- quantile(fw3, probs = 0.975)
t <- qadj975[[1]]
qadj975 <-  t[[1]]

qdat975 <- quantile(tt, probs = 0.975)
t <- qdat975[[1]]
qdat975 <- t

qadj05 <- quantile(fw3, probs = 0.05)
t <- qadj05[[1]]
qadj05 <-  t[[1]]

qdat05 <- quantile(tt, probs = 0.05)
t <- qdat05[[1]]
qdat05 <- t

qadj95 <- quantile(fw3, probs = 0.95)
t <- qadj95[[1]]
qadj95 <-  t[[1]]

qdat95 <- quantile(tt, probs = 0.95)
t <- qdat95[[1]]
qdat95 <- t


qadj075 <- quantile(fw3, probs = 0.075)
t       <- qadj075[[1]]
qadj075 <-  t[[1]]

qdat075 <- quantile(tt, probs = 0.075)
t       <- qdat075[[1]]
qdat075 <- t

qadj925 <- quantile(fw3, probs = 0.925)
t       <- qadj925[[1]]
qadj925 <-  t[[1]]

qdat925 <- quantile(tt, probs = 0.925)
t       <- qdat925[[1]]
qdat925 <- t


qadj01 <- quantile(fw3, probs = 0.1)
t       <- qadj01[[1]]
qadj01 <-  t[[1]]

qdat01 <- quantile(tt, probs = 0.1)
t       <- qdat01[[1]]
qdat01 <- t

qadj09 <- quantile(fw3, probs = 0.9)
t      <- qadj09[[1]]
qadj09 <-  t[[1]]

qdat09 <- quantile(tt, probs = 0.9)
t       <- qdat09[[1]]
qdat09 <- t

qadj0125 <- quantile(fw3, probs = 0.125)
t       <- qadj0125[[1]]
qadj0125 <-  t[[1]]

qdat0125 <- quantile(tt, probs = 0.125)
t       <- qdat0125[[1]]
qdat0125 <- t

qadj0875 <- quantile(fw3, probs = 0.875)
t      <- qadj0875[[1]]
qadj0875 <-  t[[1]]

qdat0875 <- quantile(tt, probs = 0.875)
t       <- qdat0875[[1]]
qdat0875 <- t

qadj015 <- quantile(fw3, probs = 0.15)
t       <- qadj015[[1]]
qadj015 <-  t[[1]]

qdat015 <- quantile(tt, probs = 0.15)
t       <- qdat015[[1]]
qdat015 <- t

qadj085 <- quantile(fw3, probs = 0.85)
t      <- qadj085[[1]]
qadj085 <-  t[[1]]

qdat085 <- quantile(tt, probs = 0.85)
t       <- qdat085[[1]]
qdat085 <- t

qadj0175 <- quantile(fw3, probs = 0.175)
t       <- qadj0175[[1]]
qadj0175 <-  t[[1]]

qdat0175 <- quantile(tt, probs = 0.175)
t       <- qdat0175[[1]]
qdat0175 <- t

qadj0825 <- quantile(fw3, probs = 0.825)
t      <- qadj0825[[1]]
qadj0825 <-  t[[1]]

qdat0825 <- quantile(tt, probs = 0.825)
t       <- qdat0825[[1]]
qdat0825 <- t
@
  


\subsection{Presentaci\'on de tablas}

Lo que nos da 


<<echo = FALSE, fig=TRUE>>=
hist(tt, breaks = nbreaks, col= rainbow(15,0.7), main = 'Translated Log2 Transformed Basal Expresion',xlab = 'Log2 Basal Expresion')
abline(v=2.130931, lty=2, col="darkgoldenrod4"); abline(v=6.528913, lty=2, col="darkgoldenrod4")
abline(v=1.935032, lty=2, col="darkblue"); abline(v=6.908847, lty=2, col="darkblue")
abline(v=1.744155, lty=2, col="aquamarine4"); abline(v=7.536406, lty=2, col="aquamarine4")
abline(v=1.462480, lty=2, col="green"); abline(v=7.969012, lty=2, col="green")
abline(v=1.109689, lty=2, col="brown"); abline(v=8.554710, lty=2, col="brown")
abline(v=0.8089802, lty=2, col="red"); abline(v=9.176996, lty=2, col="red")
abline(v=0.4286451, lty=2, col="blue"); abline(v=10.57361, lty=2, col="blue")
abline(v=0.1727493, lty=2, col="orange"); abline(v=13.43287, lty=2, col="orange")
legend("topright",
       legend=c("65%",
                "70%",
                "75%",
                "80%",
                "85%",
                "90%",
                "95%",
                "99%"), 
       pch=c(1,2,3,4,5,6,7,8),
       col=c("darkgoldenrod4","darkblue","aquamarine4",
             "green", "brown","red","blue","orange"))
@




\section{Expresi\'on Basal sin traslado}

Los datos del art\'iculo principal son sim\'etricos y se distribuyen normal casi perfectamente, con lo que es relativamente m\'as sencillo determinar los valores que ser\'an considerados de frecuencias bajas, medias y altas. Para nuestro caso la distribuci\'on emp\'irica es asim\'etrica, por eso no es posible replicar los mismos criterios.


%Cuantiles con el modelo ajustado
<<echo = FALSE>>=
CuantilesA <- matrix(0,8,2)
colnames(CuantilesA) <- c('LimInf','LimSup')
rownames(CuantilesA) <- c('65','70','75','80','85','90','95','99')
qadj0175 <- quantile(fw3, probs = 0.175); t <- qadj0175[[1]];qadj0175 <-  t[[1]]-1;CuantilesA[1,1] <- qadj0175; 
qadj0825 <- quantile(fw3, probs = 0.825); t <- qadj0825[[1]];qadj0825 <-  t[[1]]-1;CuantilesA[1,2] <- qadj0825; 
qadj015  <- quantile(fw3, probs = 0.15);  t <- qadj015[[1]]; qadj015  <-  t[[1]]-1;CuantilesA[2,1] <- qadj015; 
qadj085  <- quantile(fw3, probs = 0.85);  t <- qadj085[[1]]; qadj085  <-  t[[1]]-1;CuantilesA[2,2] <- qadj085; 
qadj0125 <- quantile(fw3, probs = 0.125); t <- qadj0125[[1]];qadj0125 <-  t[[1]]-1;CuantilesA[3,1] <- qadj0125; 
qadj0875 <- quantile(fw3, probs = 0.875); t <- qadj0875[[1]];qadj0875 <-  t[[1]]-1;CuantilesA[3,2] <- qadj0875; 
qadj001  <- quantile(fw3, probs = 0.1);   t <- qadj001[[1]]; qadj001  <-  t[[1]]-1;CuantilesA[4,1] <- qadj001; 
qadj009  <- quantile(fw3, probs = 0.9);   t <- qadj009[[1]]; qadj009  <-  t[[1]]-1;CuantilesA[4,2] <- qadj009; 
qadj075  <- quantile(fw3, probs = 0.075); t <- qadj075[[1]]; qadj075  <-  t[[1]]-1;CuantilesA[5,1] <- qadj075; 
qadj0925 <- quantile(fw3, probs = 0.925); t <- qadj0925[[1]];qadj0925 <-  t[[1]]-1;CuantilesA[5,2] <- qadj0925; 
qadj005  <- quantile(fw3, probs = 0.05);  t <- qadj005[[1]]; qadj005  <-  t[[1]]-1;CuantilesA[6,1] <- qadj005; 
qadj095  <- quantile(fw3, probs = 0.95);  t <- qadj095[[1]]; qadj095  <-  t[[1]]-1;CuantilesA[6,2] <- qadj095; 
qadj025  <- quantile(fw3, probs = 0.025); t <- qadj025[[1]]; qadj025  <-  t[[1]]-1;CuantilesA[7,1] <- qadj025; 
qadj0975 <- quantile(fw3, probs = 0.975); t <- qadj0975[[1]];qadj0975 <-  t[[1]]-1;CuantilesA[7,2] <- qadj0975; 
qadj005  <- quantile(fw3, probs = 0.005); t <- qadj005[[1]]; qadj005  <-  t[[1]]-1;CuantilesA[8,1] <- qadj005; 
qadj0995 <- quantile(fw3, probs = 0.995); t <- qadj0995[[1]];qadj0995 <-  t[[1]]-1;CuantilesA[8,2] <- qadj0995; 
@



Cuantiles con los datos
<<echo = FALSE>>=
CuantilesD <- matrix(0,8,2)
colnames(CuantilesD) <- c('LimInf','LimSup')
rownames(CuantilesD) <- c('65','70','75','80','85','90','95','99')
qdat0175 <- quantile(tt, probs = 0.175);  t <- qdat0175[[1]]; qdat0175 <- t-1;CuantilesD[1,1] <- qdat0175; 
qdat0825 <- quantile(tt, probs = 0.825);  t <- qdat0825[[1]]; qdat0825 <- t-1;CuantilesD[1,2] <- qdat0825
qdat015  <- quantile(tt, probs = 0.15);   t <- qdat015[[1]];  qdat015  <- t-1;CuantilesD[2,1] <- qdat015;
qdat085  <- quantile(tt, probs = 0.85);   t <- qdat085[[1]];  qdat085  <- t-1;CuantilesD[2,2] <- qdat085
qdat0125 <- quantile(tt, probs = 0.125);  t <- qdat0125[[1]]; qdat0125 <- t-1;CuantilesD[3,1] <- qdat0125;
qdat0875 <- quantile(tt, probs = 0.875);  t <- qdat0875[[1]]; qdat0875 <- t-1;CuantilesD[3,2] <- qdat0875
qdat001  <- quantile(tt, probs = 0.1);    t <- qdat001[[1]];  qdat001  <- t-1;CuantilesD[4,1] <- qdat001;
qdat09   <- quantile(tt, probs = 0.9);    t <- qdat09[[1]];   qdat09   <- t-1;CuantilesD[4,2] <- qdat09;
qdat075  <- quantile(tt, probs = 0.075);  t <- qdat075[[1]];  qdat075  <- t-1;CuantilesD[5,1] <- qdat075;
qdat0925 <- quantile(tt, probs = 0.925);  t <- qdat0925[[1]]; qdat0925 <- t-1;CuantilesD[5,2] <- qdat0925
qdat005  <- quantile(tt, probs = 0.05);   t <- qdat005[[1]];  qdat005  <- t-1;CuantilesD[6,1] <- qdat005;
qdat095  <- quantile(tt, probs = 0.95);   t <- qdat095[[1]];  qdat095  <- t-1;CuantilesD[6,2] <- qdat095 
qdat025  <- quantile(tt, probs = 0.025);  t <- qdat025[[1]];  qdat025  <- t-1;CuantilesD[7,1] <- qdat025;
qdat0975 <- quantile(tt, probs = 0.975);  t <- qdat0975[[1]]; qdat0975 <- t-1;CuantilesD[7,2] <- qdat0975
qdat005  <- quantile(tt, probs = 0.005);  t <- qdat005[[1]];  qdat005  <- t-1;CuantilesD[8,1] <- qdat005;
qdat0995 <- quantile(tt, probs = 0.995);  t <- qdat0995[[1]]; qdat0995 <- t-1;CuantilesD[8,2] <- qdat0995
print(CuantilesD)
#data.frame(CuantilesD)
@

\subsection{Presentaci\'on de tablas}

Lo que nos da las siguientes tablas

<<echo = FALSE>>=
tt<- Log2BE
@

<<echo = FALSE, fig=TRUE>>=
hist(tt, breaks = nbreaks, col= rainbow(15,0.7), xlim=c(-3,15),
     main = 'Log2 Transformed Basal Expresion', lty=9)
#===========================================================================
abline(v=CuantilesD[1,1], lty=2, col="darkgoldenrod4"); abline(v=CuantilesD[1,2], lty=2, col="darkgoldenrod4")
abline(v=CuantilesD[2,1], lty=2, col="darkblue"); abline(v=CuantilesD[2,2], lty=2, col="darkblue")
abline(v=CuantilesD[3,1], lty=2, col="aquamarine4"); abline(v=CuantilesD[3,2], lty=2, col="aquamarine4")
abline(v=CuantilesD[4,1], lty=2, col="green"); abline(v=CuantilesD[4,2], lty=2, col="green")
abline(v=CuantilesD[5,1], lty=2, col="brown"); abline(v=CuantilesD[5,2], lty=2, col="brown")
abline(v=CuantilesD[6,1], lty=2, col="red"); abline(v=CuantilesD[6,2], lty=2, col="red")
abline(v=CuantilesD[7,1], lty=2, col="blue"); abline(v=CuantilesD[7,2], lty=2, col="blue")
abline(v=CuantilesD[8,1], lty=2, col="orange"); abline(v=CuantilesD[8,2], lty=2, col="orange")
legend("topright",
       legend=c("65%",
                "70%",
                "75%",
                "80%",
                "85%",
                "90%",
                "95%",
                "99%"), 
       pch=c(1,2,3,4,5,6,7,8),
       col=c("darkgoldenrod4","darkblue","aquamarine4",
             "green", "brown","red","blue","orange"))
@

\section{Propuesta}


\subsection{Valores Altos, Moderadamente Altos, Bajos y Moderadamente Bajos}


Con base en la secci\'on anterior, se tienen que la expresi\'on basal, centrados y transformados ($Log_{2}$), tienen una distribuci\'on weibull y los cuantiles para los valores $65,70,75,80,85,90,95$ y $99$ por ciento se propone que los valores moderados altos (bajos )sean aquellos que se encuentran entre el $70\%$ y $85\%$, mientras que los valores muy altos (bajos) aquellos superiores al $85\%$: 
\begin{itemize}
\item Very Low Expression: $\left[-\infty,0.1096893\right)$,
\item Moderately Low Expression: $\left[0.1096893,0.9350316\right)$,
\item Moderate Expresion: $\left[0.9350316,5.908847\right)$,
\item Moderately High Expression: $\left[5.908847,7.55471\right)$,
\item Very High Expression: $\left[7.55471,\infty\right)$.
\end{itemize}

<<echo = FALSE, fig=TRUE>>=
hist(tt, breaks = nbreaks, col= rainbow(15,0.7), xlim=c(-3,15),
     main = 'Log2 Transformed Basal Expresion', lty=9)
#===========================================================================
#abline(v=1.130931, lty=2, col="darkgoldenrod4"); abline(v=5.5288913, lty=2, col="darkgoldenrod4")
abline(v=CuantilesD[2,1], lty=2, col="darkblue"); abline(v=CuantilesD[2,2], lty=2, col="darkblue")
#abline(v=0.7441547, lty=2, col="aquamarine4"); abline(v=6.536406, lty=2, col="aquamarine4")
#abline(v=0.4624797, lty=2, col="green"); abline(v=6.969012, lty=2, col="green")
abline(v=CuantilesD[5,1], lty=2, col="brown"); abline(v=CuantilesD[5,2], lty=2, col="brown")
#abline(v=-0.8272507, lty=2, col="red"); abline(v=8.176996, lty=2, col="red")
#abline(v=-0.5713549, lty=2, col="blue"); abline(v=9.573605, lty=2, col="blue")
#abline(v=-0.1910198, lty=2, col="orange"); abline(v=12.43287, lty=2, col="orange")
legend("topright",
       legend=c(#"65%",
                "70%",
                #"75%",
                #"80%",
                "85%"),
                #"90%",
                #"95%",
                #"99%"
#                ), 
       pch=c(1,2),#3,4,5,6,7,8),
       col=c(#"darkgoldenrod4",
#             "darkblue","aquamarine4","green",
             "brown"
             #,"red","blue","orange"
             ))
@




Con base en cualquiera de las dos opciones, se calcula la probabilidad de que dada una expresi\'on basal ($Log_{2}$) se pueda determinar a qu\'e motif pertenece, esto por medio del Teorema de Bayes. 


Para lo anterio consideremos una partici\'on para el dominio de las \textit{Expresiones Basales}: $Y=\left\{y_{1},y_{2},\ldots,y_{n}\right\}$, y una partici\'on para el dominio de las posiciones de los genes: $X=\left\{x_{1},x_{2},\ldots,x_{m}\right\}$. Adem\'as se tienen cuatro clases $\left\{C_{1},C_{2},C_{3},C_{4}\right\}$, estas clases corresponden a los motifs: $\left\{CAACGG,CAACTG,TAACGG,TAACTG\right\}$ respectivamente.

Si se hacen las siguientes consideraciones en t\'erminos de la notaci\'on: 
\begin{itemize}
\item $HB$ para las posiciones de valores altos, 
\item $HMB$ para las posiciones de valores moderados altos, 
\item $MB$ para las posiciones de valores moderados, 
\item $LMB$ para las posiciones de valores moderados bajos, 
\item $LB$ para las posiciones de valores bajos,
\end{itemize}

estos dependen de los umbrales definidos en $I$ y $II$. 


Para cada una de las clases $C_{i}$, $i=1,2,3,4$ es posible determinar:

\begin{eqnarray}\label{Eq.Bayes1}
P\left[\textrm{pertenecer a la clase }C_{i}| HB\right]=\frac{P\left[HB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[HB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}

\begin{eqnarray}\label{Eq.Bayes2}
P\left[\textrm{pertenecer a la clase }C_{i}| HMB\right]=\frac{P\left[HMB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[HMB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}


\begin{eqnarray}\label{Eq.Bayes3}
P\left[\textrm{pertenecer a la clase }C_{i}| MB\right]=\frac{P\left[MB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[MB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}

\begin{eqnarray}\label{Eq.Bayes4}
P\left[\textrm{pertenecer a la clase }C_{i}| LMB\right]=\frac{P\left[LMB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[LMB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}
y
\begin{eqnarray}\label{Eq.Bayes5}
P\left[\textrm{pertenecer a la clase }C_{i}| LB\right]=\frac{P\left[LB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[LB|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}


Incluso para cada elemento de $Y$:

\begin{eqnarray}\label{Eq.BasalClase}
P\left[\textrm{pertenecer a la clase }C_{i}| y_{k}\right]=\frac{P\left[y_{k}|C_{i}\right]P\left[C_{i}\right]}{\sum_{k=1}^{n}P\left[y_{k}|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}
para $k=1,2,\ldots,n$, donde las clases corresponden a los 4 diferentes motif's que se tienen. 


\subsection{Calculo de Probabilidades}

El procedimiento seguido fue el siguiente:
  
  \begin{itemize}
\item[I. ] Se tienen $N$ valores para la expresi\'on basal, $\left\{b_{1},b_{2},\ldots,b_{N}\right\}$, con estos se calcula tanto la media como la varianza muestral, mismas que se denotan por $\overline{B}$ y $S_{b}^{2}$. A continuaci\'on se normalizaron es decir, se les resto el valor de la media y se dividieron por la desviaci\'on est\'andar muestral:

\begin{eqnarray}
\tilde{b}_{i}=\frac{b_{i}-\overline{B}}{S_{b}},
\end{eqnarray}
posteriormente se les aplic\'o $Log_{2}$
\begin{eqnarray}
\hat{b}_{i}=Log_{2}\left(\tilde{b}_{i}\right).
\end{eqnarray}

\item[II. ] Con la ayuda del programa R-Statistics, se encontr\'o la mejor partici\'on que permite obtener una representaci\'on gr\'afica apropiada de los datos transformados, esto se obtiene al considerar $n=40$ como el tama\~no de la partici\'on que permite el mejor gr\'afico de los datos ahora llamados \textit{Log2 Transformed Basal Expresion}

\item[III. ] Se calculan las probabilidades de pertenecer a una de las cuatro clases $C_{1},C_{2},C_{3}, C_{4}$

\item[IV. ] Para cada una de las clases, considerando la partici\'on $X=\left\{x_{1},x_{2},\ldots,x_{m}\right\}$ se calculan las probabilidades de estar en $LB$, $LMB$, $MB$ $HMB$ y $HB$, es decir, se calculan las probabilidades $P\left[LB|C_{i}\right]$, $P\left[LMB|C_{i}\right]$,$P\left[HMB|C_{i}\right]$ y $P\left[HB|C_{i}\right]$, para $i=1,2,3,4$.


\item[V. ] Se utilizan las ecuaciones \ref{Eq.Bayes1}, \ref{Eq.Bayes2}, \ref{Eq.Bayes3}, \ref{Eq.Bayes4} y \ref{Eq.Bayes5}  para determinar las probabilidades de pertenecer a una de las clases $C_{i}$ dado que se sabe que se toma un valor de alta/baja expresi\'on basal

\item[VI. ] Para cada una de las clases, se calcula la probabilidad de tomar un valor en la clase, suponiendo un muestreo con reemplazo, es decir, se calculan las probabilidades $P\left[y_{k}|C_{i}\right]$, para $i=1,2,3,4$, para $k=1,2,\ldots,N$.

\item[VII. ] Con las probabilidades calculadas en el paso anterior se calculala probabilidad de pertenecer a una de las cuatro clases, considerando que se conoce el valor de la expresi\'on basal, esto se logra por medio de la ecuaci\'on \label{Eq.Basal-Clase}.
\end{itemize}

\subsection{Preguntas abiertas}

Las preguntas que quedan a\'un queda sin responder son las siguientes: 

\begin{itemize}
\item[1. ] Dado el valor de la posici\'on de un gen, es posible determinar a qu\'e motif pertenece?
\begin{eqnarray}
P\left[C_{i}|p_{i}\right]
\end{eqnarray}
donde $p_{1},p_{2},\ldots,p_{M}$ son los valores conocidos que se tienen para las posiciones de los genes, y $C_{i}, i=1,2,3,4$ corresponden a los motif's.

\item[2. ] Dado el valor de la posici\'on de un gen, es posible determinar que rango de expresi\'on basal tiene: \textit{Bajo, Bajo Moderado, Alto Moderado, Alto}?
\begin{eqnarray}
P\left[LB|p_{i}\right],P\left[LMB|p_{i}\right],P\left[HMB|p_{i}\right],P\left[HB|p_{i}\right]
\end{eqnarray}

\end{itemize}


\subsection{Respondiendo las preguntas}

\subsubsection{Clases/Motif's}
<<echo = TRUE>>=
counts<- table(bdd$Sequence)
PropSeq <- table(bdd$Sequence)
prop.table(PropSeq)
PC <- prop.table(PropSeq)
#print(PropSeq)
@

De lo anterior se desprende 
\begin{eqnarray*}
P\left[C_{1}\right]=0.05339105\\
P\left[C_{2}\right]=0.28427128\\
P\left[C_{3}\right]=0.07503608\\
P\left[C_{4}\right]=0.58730159
\end{eqnarray*}

\subsubsection{Bajas, Bajas Moderadas, Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: Todos los Datos}

Ahora contemos la cantidad de elementos que hay en las clases $HB,HMB,MB,LMB,LB$, \begin{itemize}
\item Very Low Expression: $\left[-\infty,0.1096893\right)$,
\item Moderately Low Expression: $\left[0.1096893,0.9350316\right)$,
\item Moderate Expresion: $\left[0.9350316,5.908847\right)$,
\item Moderately High Expression: $\left[5.908847,7.55471\right)$,
\item Very High Expression: $\left[7.55471,\infty\right)$.
\end{itemize}

<<echo = FALSE>>=
tt1 <- min(tt)
VLI <- tt1
VLS <- CuantilesD[5,1] - 0.0000001
MLI <- CuantilesD[5,1]
MLS <- CuantilesD[2,1] - 0.0000001
MI  <- CuantilesD[2,1]
MS  <- CuantilesD[2,2] - 0.0000001
MHI <- CuantilesD[2,2]
MHS <- CuantilesD[5,2] - 0.0000001
VHI <- CuantilesD[5,2]
VHS <- max(tt)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tt)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tt[i]>=VLI) & (tt[i]<=VLS)){ContVL<- ContVL+1;}
  if((tt[i]>=MLI) & (tt[i]<=MLS)){ContML<- ContML+1;}
  if((tt[i]>=MI)  & (tt[i]<=MS)){ContM <- ContM+1;}
  if((tt[i]>=MHI) & (tt[i]<=MHS)){ContMH<- ContMH+1;}
  if((tt[i]>=VHI) & (tt[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
Conteo <- matrix(0,2,6);
Conteo[1,1] <- ContVL
Conteo[1,2] <- ContML
Conteo[1,3] <- ContM
Conteo[1,4] <- ContMH
Conteo[1,5] <- ContVH
Conteo[1,6] <- sum(Conteo[1,])
Conteo[2,1] <- ContVL/N;
Conteo[2,2] <- ContML/N;
Conteo[2,3] <- ContM/N
Conteo[2,4] <- ContMH/N;
Conteo[2,5] <- ContVH/N;
Conteo[2,6] <- sum(Conteo[2,])
colnames(Conteo) <- c('VL','ML','M','MH','VH','Ttl')
rownames(Conteo) <- c('fr','Prob')
print(Conteo)
@

<<echo = FALSE>>=
#dataset <- cbind(CtoDatos,tt);
dataset <- cbind(bdd,tt);
summary(dataset)
@


\subsubsection{Bajas, Bajas Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: $C_{1}$}



<<echo = FALSE>>=
### Secuencia CAACGG
datos1   <- dataset %>% filter(dataset$Sequence=='CAACGG'); summary(datos1)
tt <- datos1$tt
summary(tt)
@



<<echo = FALSE>>=
tt1 <- min(tt)
VLI <- tt1
VLS <- CuantilesD[5,1] - 0.0000001
MLI <- CuantilesD[5,1]
MLS <- CuantilesD[2,1] - 0.0000001
MI  <- CuantilesD[2,1]
MS  <- CuantilesD[2,2] - 0.0000001
MHI <- CuantilesD[2,2]
MHS <- CuantilesD[5,2] - 0.0000001
VHI <- CuantilesD[5,2]
VHS <- max(tt)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tt)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tt[i]>=VLI) & (tt[i]<=VLS)){ContVL<- ContVL+1;}
  if((tt[i]>=MLI) & (tt[i]<=MLS)){ContML<- ContML+1;}
  if((tt[i]>=MI)  & (tt[i]<=MS)){ContM <- ContM+1;}
  if((tt[i]>=MHI) & (tt[i]<=MHS)){ContMH<- ContMH+1;}
  if((tt[i]>=VHI) & (tt[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
ConteoC1 <- matrix(0,2,6);
ConteoC1[1,1] <- ContVL
ConteoC1[1,2] <- ContML
ConteoC1[1,3] <- ContM
ConteoC1[1,4] <- ContMH
ConteoC1[1,5] <- ContVH
ConteoC1[1,6] <- sum(Conteo[1,])
ConteoC1[2,1] <- ContVL/N;
ConteoC1[2,2] <- ContML/N;
ConteoC1[2,3] <- ContM/N
ConteoC1[2,4] <- ContMH/N;
ConteoC1[2,5] <- ContVH/N;
ConteoC1[2,6] <- sum(ConteoC1[2,])
colnames(ConteoC1) <- c('VL','ML','M','MH','VH','Ttl')
rownames(ConteoC1) <- c('fr','Prob')
print(ConteoC1)
@


\subsubsection{Bajas, Bajas Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: $C_{2}$}


<<echo = FALSE>>=
datos2   <- dataset %>% filter(dataset$Sequence=='CAACTG'); summary(datos2)
tt <- datos2$tt
summary(tt)
@

<<echo = FALSE>>=
tt1 <- min(tt)
VLI <- tt1
VLS <- CuantilesD[5,1] - 0.0000001
MLI <- CuantilesD[5,1]
MLS <- CuantilesD[2,1] - 0.0000001
MI  <- CuantilesD[2,1]
MS  <- CuantilesD[2,2] - 0.0000001
MHI <- CuantilesD[2,2]
MHS <- CuantilesD[5,2] - 0.0000001
VHI <- CuantilesD[5,2]
VHS <- max(tt)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tt)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tt[i]>=VLI) & (tt[i]<=VLS)){ContVL<- ContVL+1;}
  if((tt[i]>=MLI) & (tt[i]<=MLS)){ContML<- ContML+1;}
  if((tt[i]>=MI)  & (tt[i]<=MS)){ContM <- ContM+1;}
  if((tt[i]>=MHI) & (tt[i]<=MHS)){ContMH<- ContMH+1;}
  if((tt[i]>=VHI) & (tt[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
ConteoC2 <- matrix(0,2,6);
ConteoC2[1,1] <- ContVL
ConteoC2[1,2] <- ContML
ConteoC2[1,3] <- ContM
ConteoC2[1,4] <- ContMH
ConteoC2[1,5] <- ContVH
ConteoC2[1,6] <- sum(Conteo[1,])
ConteoC2[2,1] <- ContVL/N;
ConteoC2[2,2] <- ContML/N;
ConteoC2[2,3] <- ContM/N
ConteoC2[2,4] <- ContMH/N;
ConteoC2[2,5] <- ContVH/N;
ConteoC2[2,6] <- sum(ConteoC2[2,])
colnames(ConteoC2) <- c('VL','ML','M','MH','VH','Ttl')
rownames(ConteoC2) <- c('fr','Prob')
print(ConteoC2)
@


\subsubsection{Bajas, Bajas Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: $C_{3}$}

<<echo = FALSE>>=
### Secuencia TAACGG
datos3   <- dataset %>% filter(dataset$Sequence=='TAACGG'); summary(datos3)
tt <- datos3$tt
summary(tt)
@


<<echo = FALSE>>=
tt1 <- min(tt)
VLI <- tt1
VLS <- CuantilesD[5,1] - 0.0000001
MLI <- CuantilesD[5,1]
MLS <- CuantilesD[2,1] - 0.0000001
MI  <- CuantilesD[2,1]
MS  <- CuantilesD[2,2] - 0.0000001
MHI <- CuantilesD[2,2]
MHS <- CuantilesD[5,2] - 0.0000001
VHI <- CuantilesD[5,2]
VHS <- max(tt)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tt)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tt[i]>=VLI) & (tt[i]<=VLS)){ContVL<- ContVL+1;}
  if((tt[i]>=MLI) & (tt[i]<=MLS)){ContML<- ContML+1;}
  if((tt[i]>=MI)  & (tt[i]<=MS)){ContM <- ContM+1;}
  if((tt[i]>=MHI) & (tt[i]<=MHS)){ContMH<- ContMH+1;}
  if((tt[i]>=VHI) & (tt[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
ConteoC3 <- matrix(0,2,6);
ConteoC3[1,1] <- ContVL
ConteoC3[1,2] <- ContML
ConteoC3[1,3] <- ContM
ConteoC3[1,4] <- ContMH
ConteoC3[1,5] <- ContVH
ConteoC3[1,6] <- sum(Conteo[1,])
ConteoC3[2,1] <- ContVL/N;
ConteoC3[2,2] <- ContML/N;
ConteoC3[2,3] <- ContM/N
ConteoC3[2,4] <- ContMH/N;
ConteoC3[2,5] <- ContVH/N;
ConteoC3[2,6] <- sum(ConteoC3[2,])
colnames(ConteoC3) <- c('VL','ML','M','MH','VH','Ttl')
rownames(ConteoC3) <- c('fr','Prob')
print(ConteoC3)
@



\subsubsection{Bajas, Bajas Moderadas, Altas Moderadas, Altas Expresiones Basales transformadas: $C_{4}$}


<<echo = FALSE>>=
### Secuencia TAACTG
datos4   <- dataset %>% filter(dataset$Sequence=='TAACTG'); summary(datos4)
tt <- datos4$tt
summary(tt)
@


<<echo = FALSE>>=
tt1 <- min(tt)
VLI <- tt1
VLS <- CuantilesD[5,1] - 0.0000001
MLI <- CuantilesD[5,1]
MLS <- CuantilesD[2,1] - 0.0000001
MI  <- CuantilesD[2,1]
MS  <- CuantilesD[2,2] - 0.0000001
MHI <- CuantilesD[2,2]
MHS <- CuantilesD[5,2] - 0.0000001
VHI <- CuantilesD[5,2]
VHS <- max(tt)
Limites <- matrix(0,1,10)
#colnames(Limites) <- c('VLI','VLS','MLI','MLS','MI','MS','MHI','MHS','VHI','VHS')
Limites <- c(VLI,VLS,MLI,MLS,MI,MS,MHI,MHS,VHI,VHS)
N <- length(tt)
ContVL<- 0;
ContML<- 0;
ContM <- 0;
ContMH<- 0;
ContVH<- 0;

for(i in 1:N){
  if((tt[i]>=VLI) & (tt[i]<=VLS)){ContVL<- ContVL+1;}
  if((tt[i]>=MLI) & (tt[i]<=MLS)){ContML<- ContML+1;}
  if((tt[i]>=MI)  & (tt[i]<=MS)){ContM <- ContM+1;}
  if((tt[i]>=MHI) & (tt[i]<=MHS)){ContMH<- ContMH+1;}
  if((tt[i]>=VHI) & (tt[i]<=VHS)){ContVH<- ContVH+1;}
#  i <- i+1
}
ConteoC4 <- matrix(0,2,6);
ConteoC4[1,1] <- ContVL
ConteoC4[1,2] <- ContML
ConteoC4[1,3] <- ContM
ConteoC4[1,4] <- ContMH
ConteoC4[1,5] <- ContVH
ConteoC4[1,6] <- sum(Conteo[1,])
ConteoC4[2,1] <- ContVL/N;
ConteoC4[2,2] <- ContML/N;
ConteoC4[2,3] <- ContM/N
ConteoC4[2,4] <- ContMH/N;
ConteoC4[2,5] <- ContVH/N;
ConteoC4[2,6] <- sum(ConteoC4[2,])
colnames(ConteoC4) <- c('VL','ML','M','MH','VH','Ttl')
rownames(ConteoC4) <- c('fr','Prob')
print(ConteoC4)
@



\subsection{Presentacion de resultados}

Es decir las probabilidades condicionales y las probabilidades de cada $C_{i}$ son

<<echo = TRUE>>=
ProbCond <- rbind(ConteoC1[2,],ConteoC2[2,],ConteoC3[2,],ConteoC4[2,])
rownames(ProbCond) <- c('PB_C1','PB_C2','PB_C3','PB_C4')
colnames(ProbCond) <- c('LB','LMB','MB','HMB','HB','Ttl_Prob')
ProbC<- matrix(0,1,4)
ProbC[1] <- PC[[1]]
ProbC[2] <- PC[[2]]
ProbC[3] <- PC[[3]]
ProbC[4] <- PC[[4]]
colnames(ProbC) <- c('C1','C2','C3','C4')
rownames(ProbC) <- c('Prob')
print(ProbC)
print(ProbCond)
@



Por tanto ya podemos determinar las probabiidades $P\left[\cdot|C_{i}\right]P\left[C_{i}\right]$
<<echo = FALSE>>=
print('calcular')
Numeradores <- matrix(0,5,4)
colnames(Numeradores) <- c('C1','C2','C3','C4')
rownames(Numeradores) <- c('LB','LMB','MB','HMB','HB')

Numeradores[1,1] <- ProbCond[1,1]*ProbC[1]
Numeradores[1,2] <- ProbCond[2,1]*ProbC[2]
Numeradores[1,3] <- ProbCond[3,1]*ProbC[3]
Numeradores[1,4] <- ProbCond[4,1]*ProbC[4]

Numeradores[2,1] <- ProbCond[1,2]*ProbC[1]
Numeradores[2,2] <- ProbCond[2,2]*ProbC[2]
Numeradores[2,3] <- ProbCond[3,2]*ProbC[3]
Numeradores[2,4] <- ProbCond[4,2]*ProbC[4]

Numeradores[3,1] <- ProbCond[1,3]*ProbC[1]
Numeradores[3,2] <- ProbCond[2,3]*ProbC[2]
Numeradores[3,3] <- ProbCond[3,3]*ProbC[3]
Numeradores[3,4] <- ProbCond[4,3]*ProbC[4]

Numeradores[4,1] <- ProbCond[1,4]*ProbC[1]
Numeradores[4,2] <- ProbCond[2,4]*ProbC[2]
Numeradores[4,3] <- ProbCond[3,4]*ProbC[3]
Numeradores[4,4] <- ProbCond[4,4]*ProbC[4]

Numeradores[5,1] <- ProbCond[1,5]*ProbC[1]
Numeradores[5,2] <- ProbCond[2,5]*ProbC[2]
Numeradores[5,3] <- ProbCond[3,5]*ProbC[3]
Numeradores[5,4] <- ProbCond[4,5]*ProbC[4]

print(Numeradores)
@


Ahora calculemos $\sum_{i=1}^{4}P\left[\cdot|C_{i}\right]P\left[C_{i}\right]$
<<echo = FALSE>>=
ProbTotal <- matrix(0,5,1)
rownames(ProbTotal) <- c('LB','LMB','MB','HMB','HB')
colnames(ProbTotal) <- c('ProbC')
ProbTotal[1] <- sum(Numeradores[1,])
ProbTotal[2] <- sum(Numeradores[2,])
ProbTotal[3] <- sum(Numeradores[3,])
ProbTotal[4] <- sum(Numeradores[4,])
ProbTotal[5] <- sum(Numeradores[5,])
print(ProbTotal)
@

para finalmente obtener $P\left[C_{i}|\cdot\right]= \frac{P\left[\cdot|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[\cdot|C_{i}\right]P\left[C_{i}\right]}$

<<echo = FALSE>>=
ProbCi_B <- matrix(0,5,4)
rownames(ProbCi_B) <- c('LB','LMB','MB','HMB','HB')
colnames(ProbCi_B) <- c('C1','C2','C3','C4')

ProbCi_B[1,1] <- Numeradores[1,1]/ProbTotal[1]
ProbCi_B[1,2] <- Numeradores[1,2]/ProbTotal[1]
ProbCi_B[1,3] <- Numeradores[1,3]/ProbTotal[1]
ProbCi_B[1,4] <- Numeradores[1,4]/ProbTotal[1]

ProbCi_B[2,1] <- Numeradores[2,1]/ProbTotal[2]
ProbCi_B[2,2] <- Numeradores[2,2]/ProbTotal[2]
ProbCi_B[2,3] <- Numeradores[2,3]/ProbTotal[2]
ProbCi_B[2,4] <- Numeradores[2,4]/ProbTotal[2]

ProbCi_B[3,1] <- Numeradores[3,1]/ProbTotal[3]
ProbCi_B[3,2] <- Numeradores[3,2]/ProbTotal[3]
ProbCi_B[3,3] <- Numeradores[3,3]/ProbTotal[3]
ProbCi_B[3,4] <- Numeradores[3,4]/ProbTotal[3]

ProbCi_B[4,1] <- Numeradores[4,1]/ProbTotal[4]
ProbCi_B[4,2] <- Numeradores[4,2]/ProbTotal[4]
ProbCi_B[4,3] <- Numeradores[4,3]/ProbTotal[4]
ProbCi_B[4,4] <- Numeradores[4,4]/ProbTotal[4]

ProbCi_B[5,1] <- Numeradores[5,1]/ProbTotal[5]
ProbCi_B[5,2] <- Numeradores[5,2]/ProbTotal[5]
ProbCi_B[5,3] <- Numeradores[5,3]/ProbTotal[5]
ProbCi_B[5,4] <- Numeradores[5,4]/ProbTotal[5]

ProbM <- ProbCi_B
print(ProbM)
@



\subsection{Tablas}

\begin{table}[h!]
\begin{center}
\scalebox{0.85}{\begin{tabular}{|l||cccc|}\hline\hline
\multirow{2}{*}{Time} & \multicolumn{4}{c|}{Propuesta 1}\\ 
& $C_{1}$&$C_{2}$&$C_{3}$& $C_{4}$\\\hline\hline
$P\left[LB|C_{i}\right]$&0.0540545&0.04060914&0.11538462&0.08845209\\
$P\left[LMB|C_{i}\right]$&0.08108108&0.06091371&0.07692308&0.08108108\\
$P\left[MB|C_{i}\right]$&0.7567568&0.7461929&0.5961538&0.6855037\\
$P\left[HMB|C_{i}\right]$&0.0270273&0.06598985&0.09615385&0.08108108\\
$P\left[HB|C_{i}\right]$&0.08108108&0.08629442&0.11538462&0.06388206\\\hline\hline
$P\left[C_{i}\right]$&0.05339105&0.28427128&0.07503608&0.058730159\\\hline\hline
$P\left[LB|C_{i}\right]P\left[C_{i}\right]$&0.002886003&0.01154401&0.008658009&0.05194805\\
$P\left[LMB|C_{i}\right]P\left[C_{i}\right]$&0.004329004&0.01731602&0.005772006&0.04761905\\
$P\left[MB|C_{i}\right]P\left[C_{i}\right]$&0.040404040&0.21212121&0.044733045&0.40259740\\
$P\left[HMB|C_{i}\right]P\left[C_{i}\right]$&0.001443001&0.01875902&0.007215007&0.04761905\\
$P\left[HB|C_{i}\right]P\left[C_{i}\right]$&0.004329004&0.02453102&0.008658009&0.03751804\\\hline\hline
$\sum_{i=1}^{4}P\left[LB|C_{i}\right]P\left[C_{i}\right]$&0.07503608&&&\\
$\sum_{i=1}^{4}P\left[LMB|C_{i}\right]P\left[C_{i}\right]$&0.07503608&&&\\
$\sum_{i=1}^{4}P\left[MB|C_{i}\right]P\left[C_{i}\right]$&0.69985570&&&\\
$\sum_{i=1}^{4}P\left[HMB|C_{i}\right]P\left[C_{i}\right]$&0.07503608&&&\\
$\sum_{i=1}^{4}P\left[HB|C_{i}\right]P\left[C_{i}\right]$&0.07503608&&&\\\hline\hline
$P\left[C_{i}|LB\right]=\frac{P\left[LB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[LB|C_{i}\right]P\left[C_{i}\right]}$&0.03846154&0.1538462&0.11538462&0.6923077\\
$P\left[C_{i}|LMB\right]=\frac{P\left[LMB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[LMB|C_{i}\right]P\left[C_{i}\right]}$&0.05769231&0.2307692&0.07692308&0.6346154\\
$P\left[C_{i}|MB\right]=\frac{P\left[MB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[MB|C_{i}\right]P\left[C_{i}\right]}$&0.05773196&0.3030928&0.06391753&0.5752577\\
$P\left[C_{i}|HMB\right]=\frac{P\left[HMB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[HMB|C_{i}\right]P\left[C_{i}\right]}$&0.01923077&0.2500000&0.09615385&0.6346154\\
$P\left[C_{i}|HB\right]=\frac{P\left[HB|C_{i}\right]P\left[C_{i}\right]}{\sum_{i=1}^{4}P\left[HB|C_{i}\right]P\left[C_{i}\right]}$&0.05769231&0.3269231&0.11538462&0.5000000\\\hline\hline
\end{tabular}}
\caption{Probabilidades Condicionales Modelo 1}
\label{tab:Simulation.Results}
\end{center}
\end{table}




\section{Pendientes}

\begin{itemize}
\item Incluir una nueva categor\'ia para valores moderados, el \'area gris del art\'iculo: Moderate

\item Lista de genes por las categor\'ias: muy bajo, moderadamente bajos, moderados, moderadamente altos y muy altos.
\item dado el valor de un gen determinar en qu\'e categor\'ia est\'a: LB,MLB,MB,HMB,HB.


\end{itemize}

\subsection*{Expresion Basal Muy Baja}
<<echo = FALSE>>=
### Secuencia TAACGG
EBVL   <- dataset %>% filter(dataset$tt>=VLI & dataset$tt<=VLS); 
ExpBasalVL <- EBVL[,c('Gen_Id','Sequence','Position','BasalExp','tt')]
colnames(ExpBasalVL) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalVL,"ExpBasalMuyBaja.csv")
summary(ExpBasalVL)
@

\subsection*{Expresion Basal Moderada Baja}

<<echo = FALSE>>=
EBML   <- dataset %>% filter(dataset$tt>=MLI & dataset$tt<=MLS); 
ExpBasalML <- EBML[,c('Gen_Id','Sequence','Position','BasalExp','tt')]
colnames(ExpBasalML) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalML,"ExpBasalModBaja.csv")
summary(ExpBasalML)
@

\subsection*{Expresion Basal Moderada}

<<echo = FALSE>>=
EBM   <- dataset %>% filter(dataset$tt>=MI & dataset$tt<=MS); 
ExpBasalM <- EBM[,c('Gen_Id','Sequence','Position','BasalExp','tt')]
colnames(ExpBasalM) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalM,"ExpBasalModerada.csv")
summary(ExpBasalM)
@

\subsection*{Expresion Basal Moderada Alta}

<<echo = FALSE>>=
EBMH   <- dataset %>% filter(dataset$tt>=MHI & dataset$tt<=MHS); 
ExpBasalMH <- EBMH[,c('Gen_Id','Sequence','Position','BasalExp','tt')]
colnames(ExpBasalMH) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalMH,"ExpBasalModAlta.csv")
summary(ExpBasalMH)
@

\subsection*{Expresion Basal Muy Alta}
<<echo = FALSE>>=
EBVH   <- dataset %>% filter(dataset$tt>=VHI & dataset$tt<=VHS); 
ExpBasalVH <- EBVH[,c('Gen_Id','Sequence','Position','BasalExp','tt')]
colnames(ExpBasalVH) <- c('Gen_Id','Sequence','Position','BasalExp','NormLog2Basal')
write.csv(ExpBasalVH,"ExpBasalMuyAlta.csv")
summary(ExpBasalVL)
@


\section{Pendientes}

\begin{itemize}
\item Incluir una nueva categor\'ia para valores moderados, el \'area gris del art\'iculo: Moderate, \textbf{ATENDIDA}

\item Lista de genes por las categor\'ias: muy bajo, moderadamente bajos, moderadamente altos y muy altos, \textbf{ATENDIDA}
\item dado el valor de un gen determinar en qu\'e categor\'ia est\'a: LB,MLB,HMB,HB.
\item Se va a utilizar el Modelo 2, \textbf{ATENDIDA}

\item Incluir 

\end{itemize}


\section{Respondiendo Pregunta abierta}

Recordemos que se considera una partici\'on para el dominio de las \textit{Expresiones Basales}: $Y=\left\{y_{1},y_{2},\ldots,y_{n}\right\}$, y una partici\'on para el dominio de las posiciones de los genes: $X=\left\{x_{1},x_{2},\ldots,x_{m}\right\}$. Adem\'as se tienen cuatro clases $\left\{C_{1},C_{2},C_{3},C_{4}\right\}$, estas clases corresponden a los motifs: $\left\{CAACGG,CAACTG,TAACGG,TAACTG\right\}$ respectivamente.

Recordemos que para cada elemento de $Y$ es posible determina la Probabilidad de pertenecer a una determinada clase dependiendo de su expresi\'on basal por medio de la ecuaci\'on:

\begin{eqnarray}\label{Eq.BasalClase}
P\left[\textrm{pertenecer a la clase }C_{i}| y_{k}\right]=\frac{P\left[y_{k}|C_{i}\right]P\left[C_{i}\right]}{\sum_{k=1}^{n}P\left[y_{k}|C_{i}\right]P\left[C_{i}\right]}
\end{eqnarray}
para $k=1,2,\ldots,n$, donde las clases corresponden a los 4 diferentes motif's que se tienen.


\end{document}